import streamlit as st
import pandas as pd
import numpy as np
import time
import matplotlib.pyplot as plt
import datetime
from datetime import timedelta
import plotly.graph_objects as go
import yfinance as yf
import plotly.express as px
import math
import threading
import warnings
import sqlite3
from sqlalchemy import create_engine, inspect, text, Column, Integer, Float, String, DateTime, JSON, Boolean
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker, scoped_session
import os
import re
import io
import sys
import json
import logging
from contextlib import redirect_stdout
import traceback
from typing import Dict, List, Tuple, Optional, Union, Any
import openai
import seaborn as sns
import subprocess
import pickle  # Model kaydetmek iÃ§in gerekli

# DÃœZELTME: GeliÅŸtirilmiÅŸ news_tab dosyasÄ±nÄ± kullan
from ui.news_tab import analyze_news, get_sentiment_explanation, display_log_message

warnings.filterwarnings("ignore")

# data modÃ¼lÃ¼nÃ¼ sys.path'e ekle (eÄŸer farklÄ± klasÃ¶rdeyse)
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
data_dir = os.path.join(parent_dir, 'data')

# VeritabanÄ± dosyasÄ± yolu
DB_FILE = os.path.join(parent_dir, 'data', 'stock_analysis.db')

if data_dir not in sys.path:
    sys.path.append(data_dir)

# news_data modÃ¼lÃ¼nÃ¼ import et
try:
    # import news_data # Eski import kaldÄ±rÄ±ldÄ±
    from data.news_data import get_stock_news # DoÄŸrudan fonksiyon import edildi
    from ui.news_tab import analyze_news, get_sentiment_explanation, display_log_message
    # VeritabanÄ± iÅŸlemleri iÃ§in importlarÄ± ekle
    from data.db_utils import (
        save_ml_prediction, 
        get_ml_predictions, 
        update_ml_prediction_result,
        get_ml_prediction_stats,
        save_ml_model,  # Model kaydetme fonksiyonu eklendi
        load_ml_model,  # Model yÃ¼kleme fonksiyonu eklendi
        DB_FILE
    )
except ImportError as e:
    st.error(f"Gerekli modÃ¼ller import edilemedi: {e}")
    st.stop()

# Loglama ayarlarÄ± (diÄŸer modÃ¼lde tanÄ±mlÄ± logger'Ä± kullanabiliriz)
# logger = logging.getLogger(__name__)
# VEYA burada yeni bir logger tanÄ±mlayabiliriz
# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
# logger = logging.getLogger(__name__)

def render_ml_prediction_tab():
    st.header("ML YÃ¼kseliÅŸ Tahmini", divider="rainbow")
    st.markdown("""
    Bu sekme, makine Ã¶ÄŸrenmesi (sÄ±nÄ±flandÄ±rma) kullanarak seÃ§ilen zaman dilimi sonunda belirlediÄŸiniz eÅŸik deÄŸerinden **daha fazla yÃ¼kselecek** hisseleri tahmin eder.
    Tahminler, modelin bu yÃ¼kseliÅŸin gerÃ§ekleÅŸme **olasÄ±lÄ±ÄŸÄ±nÄ±** ne kadar gÃ¶rdÃ¼ÄŸÃ¼nÃ¼ gÃ¶sterir.

    **GELÄ°ÅTÄ°RÄ°LMÄ°Å MODEL**: Fibonacci, Elliott DalgalarÄ±, DÃ¶viz KurlarÄ±, Makroekonomik GÃ¶stergeler ve SektÃ¶rel Analizleri iÃ§eren daha kapsamlÄ± bir veri seti ile Ã§alÄ±ÅŸabilir.

    **Not:** Tahminler yatÄ±rÄ±m tavsiyesi niteliÄŸi taÅŸÄ±maz. Sadece bilgi amaÃ§lÄ±dÄ±r.
    """)

    # VERÄ° KALÄ°TESÄ° KONTROL PANELÄ°
    with st.expander("ğŸ”§ Veri Kalitesi Kontrol Paneli", expanded=False):
        st.markdown("""
        **Ã–nemli:** ML tarama sonuÃ§larÄ±nda hisse fiyatlarÄ± gÃ¼ncel deÄŸilse bu paneli kullanÄ±n.
        """)
        
        # Ä°lk satÄ±r - Cache ve Model Temizleme
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ”„ Cache Temizle", help="TÃ¼m cache'lenmiÅŸ verileri temizler", use_container_width=True):
                st.cache_data.clear()
                st.success("âœ… Cache temizlendi! Sayfa yeniden yÃ¼klenecek.")
                st.rerun()
        
        with col2:
            if st.button("ğŸ—‘ï¸ Eski Modelleri Temizle", help="7 gÃ¼nden eski modelleri veritabanÄ±ndan siler", use_container_width=True):
                try:
                    from data.db_utils import DB_FILE
                    import sqlite3
                    from datetime import datetime, timedelta
                    
                    conn = sqlite3.connect(DB_FILE)
                    cursor = conn.cursor()
                    
                    # 7 gÃ¼nden eski modelleri bul
                    seven_days_ago = (datetime.now() - timedelta(days=7)).strftime("%Y-%m-%d %H:%M:%S")
                    
                    # Ã–nce kaÃ§ model silineceÄŸini kontrol et
                    cursor.execute("SELECT COUNT(*) FROM ml_models WHERE last_update_date < ? OR last_update_date IS NULL", (seven_days_ago,))
                    old_models_count = cursor.fetchone()[0]
                    
                    if old_models_count > 0:
                        # Eski modelleri sil
                        cursor.execute("DELETE FROM ml_models WHERE last_update_date < ? OR last_update_date IS NULL", (seven_days_ago,))
                        conn.commit()
                        
                        st.success(f"âœ… {old_models_count} eski model temizlendi!")
                    else:
                        st.info("â„¹ï¸ Temizlenecek eski model bulunamadÄ±.")
                    
                    conn.close()
                    
                except Exception as e:
                    st.error(f"âŒ Model temizleme hatasÄ±: {str(e)}")
        
        with col3:
            if st.button("ğŸ“Š Model Ä°statistikleri", help="VeritabanÄ±ndaki modelleri listeler", use_container_width=True):
                try:
                    from data.db_utils import DB_FILE
                    import sqlite3
                    from datetime import datetime, timedelta
                    
                    conn = sqlite3.connect(DB_FILE)
                    cursor = conn.cursor()
                    
                    # Toplam model sayÄ±sÄ±
                    cursor.execute("SELECT COUNT(*) FROM ml_models WHERE is_active = 1")
                    total_models = cursor.fetchone()[0]
                    
                    # Eski model sayÄ±sÄ±
                    seven_days_ago = (datetime.now() - timedelta(days=7)).strftime("%Y-%m-%d %H:%M:%S")
                    cursor.execute("SELECT COUNT(*) FROM ml_models WHERE is_active = 1 AND (last_update_date < ? OR last_update_date IS NULL)", (seven_days_ago,))
                    old_models = cursor.fetchone()[0]
                    
                    # Yeni model sayÄ±sÄ±
                    new_models = total_models - old_models
                    
                    st.info(f"ğŸ“Š **Model Ä°statistikleri:**\n- Toplam: {total_models}\n- GÃ¼ncel (â‰¤7 gÃ¼n): {new_models}\n- Eski (>7 gÃ¼n): {old_models}")
                    
                    conn.close()
                    
                except Exception as e:
                    st.error(f"âŒ Ä°statistik hatasÄ±: {str(e)}")
        
        # Ä°kinci satÄ±r - Fiyat KontrolÃ¼
        st.markdown("---")
        
        col4, col5 = st.columns(2)
        
        with col4:
            test_symbol = st.text_input("Test Edilecek Hisse", value="GARAN", placeholder="GARAN")
        
        with col5:
            if st.button("ğŸ’° AnlÄ±k Fiyat Kontrol", help="Belirtilen hissenin gerÃ§ek zamanlÄ± fiyatÄ±nÄ± kontrol eder", use_container_width=True):
                if test_symbol:
                    try:
                        import yfinance as yf
                        test_ticker = yf.Ticker(f"{test_symbol}.IS")
                        
                        # fast_info ile dene
                        try:
                            fast_info = test_ticker.fast_info
                            if hasattr(fast_info, 'last_price') and fast_info.last_price is not None:
                                st.success(f"**{test_symbol}** anlÄ±k fiyat: **{fast_info.last_price:.2f} TL** (fast_info)")
                            else:
                                raise Exception("fast_info baÅŸarÄ±sÄ±z")
                        except:
                            # info ile dene
                            info = test_ticker.info
                            price_found = False
                            for key in ['regularMarketPrice', 'currentPrice', 'previousClose']:
                                if key in info and info[key] is not None:
                                    st.success(f"**{test_symbol}** anlÄ±k fiyat: **{info[key]:.2f} TL** ({key})")
                                    price_found = True
                                    break
                            
                            if not price_found:
                                st.error(f"âŒ {test_symbol} iÃ§in anlÄ±k fiyat alÄ±namadÄ±")
                        
                        # Son kapanÄ±ÅŸ da gÃ¶ster
                        hist = test_ticker.history(period="1d")
                        if not hist.empty:
                            st.info(f"Son kapanÄ±ÅŸ: **{hist['Close'].iloc[-1]:.2f} TL**")
                        
                    except Exception as e:
                        st.error(f"âŒ Fiyat kontrolÃ¼ hatasÄ±: {str(e)}")
                else:
                    st.warning("âš ï¸ LÃ¼tfen test edilecek hisse kodunu girin")
    
    st.divider()

    # Ä°ÅŸlem gÃ¼nlÃ¼ÄŸÃ¼ iÃ§in expander oluÅŸtur (VarsayÄ±lan kapalÄ± olsun)
    log_expander = st.expander("Ä°ÅŸlem GÃ¼nlÃ¼ÄŸÃ¼ (Detaylar iÃ§in tÄ±klayÄ±n)", expanded=False)

    # Gerekli kÃ¼tÃ¼phanelerin kontrolÃ¼ ve yÃ¼klenmesi
    libs_installed = True
    try:
        import xgboost as xgb
        import lightgbm as lgb
        from sklearn.preprocessing import MinMaxScaler
        from sklearn.ensemble import RandomForestClassifier
        from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
        import numpy as np
        import matplotlib.pyplot as plt
        import pandas as pd
        import yfinance as yf
        import traceback # Hata ayÄ±klama iÃ§in
        import matplotlib # Grafik Ã§izimi iÃ§in backend ayarÄ±
        import warnings
        import io
        import sys
        from contextlib import redirect_stdout, redirect_stderr
        
        # LightGBM uyarÄ±larÄ±nÄ± bastÄ±r
        warnings.filterwarnings("ignore", category=UserWarning, module="lightgbm")
        warnings.filterwarnings("ignore", category=UserWarning, module="sklearn")
        warnings.filterwarnings("ignore", category=pd.errors.PerformanceWarning)
        
        matplotlib.use('Agg') # Streamlit ile uyumlu backend
    except ImportError as e:
        libs_installed = False
        st.error(f"Gerekli kÃ¼tÃ¼phane/kÃ¼tÃ¼phaneler eksik: {e}. LÃ¼tfen `pip install xgboost lightgbm scikit-learn numpy matplotlib pandas yfinance` komutu ile yÃ¼kleyin.")
        st.stop() # KÃ¼tÃ¼phaneler yoksa devam etme
    
    # VeritabanÄ±nÄ±n oluÅŸtuÄŸundan emin olalÄ±m
    try:
        # VeritabanÄ± kontrol edelim
        from data.db_utils import create_database, DB_FILE
        import os
        import sqlite3
        
        # VeritabanÄ± yoksa oluÅŸtur
        if not os.path.exists(DB_FILE):
            st.info("VeritabanÄ± oluÅŸturuluyor...")
            create_database()
            st.success("VeritabanÄ± baÅŸarÄ±yla oluÅŸturuldu.")
        
        # ml_models tablosu var mÄ± kontrol et
        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='ml_models'")
        if cursor.fetchone() is None:
            st.warning("ml_models tablosu bulunamadÄ±. Yeniden oluÅŸturuluyor...")
            create_database()
            st.success("VeritabanÄ± tablolarÄ± yeniden oluÅŸturuldu.")
        conn.close()
    except Exception as db_error:
        st.error(f"VeritabanÄ± kontrolÃ¼ sÄ±rasÄ±nda hata: {str(db_error)}")

    # Gemini API entegrasyonu
    gemini_pro = None
    
    # Ã–nce google-generativeai yÃ¼klÃ¼ mÃ¼ kontrol et, deÄŸilse yÃ¼klemeyi dene
    try:
        import google.generativeai as genai
    except ImportError:
        st.warning("Google GenerativeAI kÃ¼tÃ¼phanesi yÃ¼kleniyor... Bu iÅŸlem biraz zaman alabilir.")
        try:
            # KÃ¼tÃ¼phaneyi yÃ¼klemeyi dene
            subprocess.check_call([sys.executable, "-m", "pip", "install", "google-generativeai"])
            st.success("Google GenerativeAI kÃ¼tÃ¼phanesi baÅŸarÄ±yla yÃ¼klendi!")
            # YÃ¼klemeden sonra tekrar import etmeyi dene
            try:
                import google.generativeai as genai
            except ImportError:
                st.error("KÃ¼tÃ¼phane yÃ¼klendi ancak import edilemedi. UygulamayÄ± yeniden baÅŸlatmanÄ±z gerekebilir.")
        except Exception as install_error:
            st.error(f"KÃ¼tÃ¼phane yÃ¼klenirken hata oluÅŸtu: {str(install_error)}")
    
    # API anahtarÄ± ve model yapÄ±landÄ±rmasÄ±
    try:
        # API anahtarÄ±nÄ± config.py'den almaya Ã§alÄ±ÅŸ
        try:
            from config import API_KEYS
            GEMINI_API_KEY = API_KEYS.get("GEMINI_API_KEY")
            with log_expander:
                st.info("API anahtarÄ± config.py'den alÄ±ndÄ±.")
        except (ImportError, AttributeError):
            # Ortam deÄŸiÅŸkeninden almaya Ã§alÄ±ÅŸ
            GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
            with log_expander:
                st.info("API anahtarÄ± ortam deÄŸiÅŸkeninden alÄ±nmaya Ã§alÄ±ÅŸÄ±ldÄ±.")
        
        # API anahtarÄ± hala bulunamadÄ±ysa varsayÄ±lan kullan
        if not GEMINI_API_KEY:
            # VarsayÄ±lan bir API anahtarÄ± kullan
            GEMINI_API_KEY = "AIzaSyANEpZjZCV9zYtUsMJ5BBgMzkrf8yu8kM8"  # VarsayÄ±lan API anahtarÄ±
            with log_expander:
                st.info("Gemini API anahtarÄ± bulunamadÄ±. VarsayÄ±lan API anahtarÄ± kullanÄ±lÄ±yor.")
        
        genai.configure(api_key=GEMINI_API_KEY)
        
        with log_expander:
            st.success("Gemini API anahtarÄ± yapÄ±landÄ±rÄ±ldÄ±.")
            
        # FarklÄ± model adlarÄ±nÄ± en yeniden eskiye ve en iyiden kÃ¶tÃ¼ye doÄŸru sÄ±rala
        model_options = [
            'gemini-1.0-pro', 'gemini-1.0-pro-latest', 'gemini-pro',
            'gemini-1.5-flash-latest', 'gemini-1.5-flash', 'gemini-1.5-pro-latest',
            'gemini-1.5-pro', 'gemini-pro-vision'
        ]
            
        successful_model = None
        for model_name in model_options:
            try:
                test_model = genai.GenerativeModel(model_name)
                # Test et
                response = test_model.generate_content("Merhaba")
                # BaÅŸarÄ±lÄ± ise kaydet
                gemini_pro = test_model
                with log_expander:
                    st.success(f"Gemini API baÄŸlantÄ±sÄ± kuruldu: {model_name} modeli kullanÄ±lÄ±yor.")
                break
            except Exception as model_error:
                with log_expander:
                    st.warning(f"{model_name} modeli test edilirken hata: {str(model_error)}")
                continue
            
        if gemini_pro is None:
            with log_expander:
                st.warning("Gemini API modellerine eriÅŸilemedi. DuyarlÄ±lÄ±k analizi kullanÄ±lamayacak.")
            # DuyarlÄ±lÄ±k analizi kapalÄ±
            use_sentiment_analysis = False
    except Exception as e:
        with log_expander:
            st.warning(f"Gemini API kurulumu hatasÄ±: {str(e)}")
        # DuyarlÄ±lÄ±k analizi kapalÄ±
        use_sentiment_analysis = False

    # Parametreler
    col1, col2, col3 = st.columns(3)

    with col1:
        # EÅŸik deÄŸeri slider'Ä±
        ml_threshold = st.slider("YÃ¼kseliÅŸ EÅŸiÄŸi (%)", min_value=0.5, max_value=10.0, value=2.0, step=0.5, key="ml_pred_threshold", help="Modelin hangi yÃ¼zdelik artÄ±ÅŸÄ±n Ã¼zerini 'YÃ¼kseliÅŸ' olarak sÄ±nÄ±flandÄ±racaÄŸÄ±nÄ± belirler.") / 100

    with col2:
        scan_option = st.radio(
            "Tarama Modu:",
            ["BIST 30", "BIST 50", "BIST 100", "TÃ¼m BIST", "Ã–zel Liste"],
            index=2,
            horizontal=True,
            key="ml_scan_option"
        )

    with col3:
        time_frame = st.selectbox(
            "Zaman Dilimi",
            ["4 Saat", "1 GÃ¼n", "1 Hafta", "1 Ay"],
            index=1,
            key="ml_time_frame"
        )

    # Ã–zel liste seÃ§eneÄŸi iÃ§in hisse giriÅŸ alanÄ±
    custom_stocks = ""
    if scan_option == "Ã–zel Liste":
        custom_stocks = st.text_area(
            "Hisse KodlarÄ± (virgÃ¼lle ayÄ±rÄ±n)",
            placeholder="Ã–rnek: THYAO, GARAN, ASELS",
            help="Analiz etmek istediÄŸiniz hisse kodlarÄ±nÄ± virgÃ¼lle ayÄ±rarak girin (.IS uzantÄ±sÄ± otomatik eklenecektir).",
            key="ml_custom_stocks"
        )
        # Hisse kodlarÄ±nÄ± regex ile filtrele
        if custom_stocks:
            stock_list = [s.strip().upper() for s in custom_stocks.split(",") if re.match(r"^[A-Z]{4,5}$", s.strip().upper())]
            if not stock_list:
                st.error("GeÃ§erli hisse kodu girilmedi. LÃ¼tfen sadece harflerden oluÅŸan 4 veya 5 karakterli BIST kodlarÄ± girin.")
                return
        else:
            stock_list = []
    else:
        stock_list = []

    # GeliÅŸmiÅŸ ayarlar
    with st.expander("GeliÅŸmiÅŸ Ayarlar"):
        adv_col1, adv_col2 = st.columns(2)

        with adv_col1:
            confidence_threshold = st.slider(
                "Minimum YÃ¼kseliÅŸ OlasÄ±lÄ±ÄŸÄ± (%)",
                min_value=40,
                max_value=95,
                value=60, # Daha makul bir varsayÄ±lan
                key="ml_confidence_threshold",
                help="Bir hissenin 'YÃ¼kseliÅŸ' olarak etiketlenmesi iÃ§in modelin tahmin etmesi gereken minimum olasÄ±lÄ±k."
            )

            feature_importance = st.checkbox(
                "Ã–zellik Ã–nemini GÃ¶ster",
                value=True,
                key="ml_feature_importance",
                help="Modelin hangi faktÃ¶rleri daha Ã¶nemli bulduÄŸunu gÃ¶sterir."
            )

            backtesting = st.checkbox(
                "Geriye DÃ¶nÃ¼k Test (Test Seti)",
                value=True,
                key="ml_backtesting",
                help="Modelin geÃ§miÅŸ verinin bir kÄ±smÄ±ndaki (test seti) performansÄ±nÄ± gÃ¶sterir."
            )

            use_advanced_features = st.checkbox(
                "GeliÅŸmiÅŸ Teknik GÃ¶stergeler",
                value=False, # VarsayÄ±lan olarak kapalÄ±, daha hÄ±zlÄ± tarama iÃ§in
                key="ml_use_advanced_features",
                help="Fibonacci, Elliott DalgalarÄ±, Hacim analizleri gibi geliÅŸmiÅŸ gÃ¶stergeleri ekler."
            )
            
        with adv_col2:
            model_selection = st.selectbox(
                "KullanÄ±lacak Model",
                ["RandomForest", "XGBoost", "LightGBM", "Ensemble", "Hibrit Model"],
                index=0,
                key="ml_model_selection",
                help="ML tahmininde kullanÄ±lacak model tÃ¼rÃ¼."
            )

            # Zaman dilimine baÄŸlÄ± olarak tahmin gÃ¼n sayÄ±sÄ±nÄ± ayarla
            if time_frame == "4 Saat":
                days_prediction = 1  # 1 gÃ¼n
            elif time_frame == "1 GÃ¼n":
                days_prediction = 1  # 1 gÃ¼n
            elif time_frame == "1 Hafta":
                days_prediction = 7  # 1 hafta
            else:  # 1 Ay
                days_prediction = 30  # 1 ay
            
            include_sentiment = st.checkbox(
                "DuyarlÄ±lÄ±k Analizini Dahil Et",
                value=False,
                key="ml_include_sentiment",
                help="Haberler ve sosyal medyadan toplanan duyarlÄ±lÄ±k verilerini modele dahil eder."
            )
            
            # DeÄŸiÅŸken adÄ± dÃ¼zeltme
            use_sentiment_analysis = include_sentiment
            
            include_macro_data = st.checkbox(
                "Makro Verileri Dahil Et",
                value=False,
                key="ml_include_macro",
                help="DÃ¶viz kurlarÄ±, enflasyon, sektÃ¶r performansÄ± gibi makro verileri modele dahil eder."
            )
            
            # DeÄŸiÅŸken adÄ± dÃ¼zeltme
            use_macro_sector_data = include_macro_data
            
            include_market_sentiment = st.checkbox(
                "BIST 100 Verilerini Dahil Et",
                value=True,
                key="ml_include_market_sentiment",
                help="BIST 100 endeksinin teknik gÃ¶stergelerini modele dahil eder."
            )
            
        # VeritabanÄ± Model AyarlarÄ± altbÃ¶lÃ¼mÃ¼
        st.markdown("#### VeritabanÄ± Model AyarlarÄ±")
        st.warning("""
        âš ï¸ **VERÄ° KALÄ°TESÄ° UYARISI:** Eski modeller gÃ¼ncel olmayan fiyatlarla eÄŸitilmiÅŸ olabilir!
        
        **Ã–nerilen Ayarlar:**
        - âŒ Ã–nceden EÄŸitilmiÅŸ Modelleri Kullan: **KAPALI** (GÃ¼ncel verilerle yeni modeller eÄŸitilsin)
        - âœ… TÃ¼m Modelleri Yeniden EÄŸit: **AÃ‡IK** (En gÃ¼ncel fiyatlarla eÄŸitim yapÄ±lsÄ±n)
        """)
        st.info("Otomatik yaÅŸ kontrolÃ¼: 7 gÃ¼nden eski modeller otomatik olarak yeniden eÄŸitilir.")
        
        db_col1, db_col2 = st.columns(2)
        
        with db_col1:
            use_db_models = st.checkbox(
                "Ã–nceden EÄŸitilmiÅŸ Modelleri Kullan", 
                value=False,  # VERÄ° KALÄ°TESÄ° Ä°Ã‡Ä°N VARSAYILAN KAPALI
                key="ml_use_db_models",
                help="âš ï¸ Eski modeller gÃ¼ncel olmayan fiyatlarla eÄŸitilmiÅŸ olabilir. Sadece 7 gÃ¼nden yeni modeller kullanÄ±lÄ±r."
            )
            
            auto_train_missing = st.checkbox(
                "Eksik Modelleri Otomatik EÄŸit", 
                value=True,
                key="ml_auto_train_missing",
                help="VeritabanÄ±nda bulunmayan hisseler iÃ§in otomatik model eÄŸitimi yapar."
            )
            
        with db_col2:
            force_retrain = st.checkbox(
                "TÃ¼m Modelleri Yeniden EÄŸit", 
                value=True,  # VERÄ° KALÄ°TESÄ° Ä°Ã‡Ä°N VARSAYILAN AÃ‡IK
                key="ml_force_retrain",
                help="âœ… Ã–nerilen: TÃ¼m hisseler iÃ§in gÃ¼ncel verilerle yeni model eÄŸitir."
            )
            
            if st.checkbox(
                "VeritabanÄ± Model Ä°statistiklerini GÃ¶ster", 
                value=False,
                key="ml_show_db_stats"
            ):
                # VeritabanÄ±nda kaÃ§ model kayÄ±tlÄ± olduÄŸunu gÃ¶ster
                from data.db_utils import DB_FILE
                import sqlite3
                
                try:
                    conn = sqlite3.connect(DB_FILE)
                    cursor = conn.cursor()
                    cursor.execute("SELECT COUNT(*) FROM ml_models WHERE is_active = 1")
                    total_models = cursor.fetchone()[0]
                    
                    cursor.execute("SELECT model_type, COUNT(*) FROM ml_models WHERE is_active = 1 GROUP BY model_type")
                    model_counts = cursor.fetchall()
                    
                    conn.close()
                    
                    st.write(f"VeritabanÄ±nda toplam **{total_models}** model bulunuyor.")
                    
                    # Model tipine gÃ¶re daÄŸÄ±lÄ±mÄ± gÃ¶ster
                    if model_counts:
                        model_stats = pd.DataFrame(model_counts, columns=["Model Tipi", "Adet"])
                        st.dataframe(model_stats, use_container_width=True)
                except Exception as e:
                    st.error(f"VeritabanÄ± istatistikleri alÄ±nÄ±rken hata: {str(e)}")

    # --- YardÄ±mcÄ± Fonksiyonlar ---
    @st.cache_data(ttl=300) # Veriyi 5 dakika cache'le (daha sÄ±k gÃ¼ncelleme)
    def get_stock_data_cached(symbol, period="5y", interval="1d", handle_missing=True, cache_key_suffix=""):
        try:
            # Log mesajlarÄ±nÄ± sadece log_expander varsa gÃ¶ster
            if 'log_expander' in globals() and log_expander is not None:
                with log_expander:
                    st.info(f"----->>> [{symbol}] yfinance.Ticker Ã§aÄŸrÄ±lÄ±yor... (Period: {period}, Interval: {interval})")
            
            # Veriyi al
            stock = yf.Ticker(symbol)
            data = stock.history(period=period, interval=interval)
            
            # Veri durumunu sadece log_expander varsa logla
            if 'log_expander' in globals() and log_expander is not None:
                with log_expander:
                    if data.empty:
                        st.warning(f"----->>> [{symbol}] yfinance'den boÅŸ veri dÃ¶ndÃ¼.")
                    else:
                        st.success(f"----->>> [{symbol}] yfinance'den veri alÄ±ndÄ± ({len(data)} satÄ±r).")
            
            # BoÅŸ veri kontrolÃ¼ - ARTIK SÄ°MÃœLASYON KULLANMA, GERÃ‡EK VERÄ° AL
            if data.empty:
                # FarklÄ± periyotlarÄ± dene
                for backup_period in ["1y", "6mo", "3mo", "1mo", "5d"]:
                    if backup_period != period:
                        try:
                            data = stock.history(period=backup_period, interval=interval)
                            if not data.empty:
                                if 'log_expander' in globals() and log_expander is not None:
                                    with log_expander:
                                        st.info(f"----->>> [{symbol}] {backup_period} periyodu ile veri alÄ±ndÄ±.")
                                break
                        except:
                            continue
                
                # Hala boÅŸsa None dÃ¶ndÃ¼r (simÃ¼lasyon kullanma)
                if data.empty:
                    if 'log_expander' in globals() and log_expander is not None:
                        with log_expander:
                            st.error(f"----->>> [{symbol}] iÃ§in hiÃ§bir periyotta veri alÄ±namadÄ±!")
                    return None
            
            # Tarih damgasÄ±nÄ± UTC'den arÄ±ndÄ±r
            if data.index.tz is not None:
                data.index = data.index.tz_localize(None)
            
            # Eksik veri iÅŸleme - geliÅŸmiÅŸ yÃ¶ntemler
            if handle_missing and not data.empty:
                # Eksik deÄŸerlerin oranÄ±nÄ± kontrol et
                missing_ratio = data.isnull().sum() / len(data)
                
                if 'log_expander' in globals() and log_expander is not None:
                    with log_expander:
                        if missing_ratio.max() > 0:
                            st.info(f"----->>> [{symbol}] Eksik veri oranÄ±: {missing_ratio[missing_ratio > 0].to_dict()}")
                
                # Fiyat verilerini OHLC deÄŸerlerini kullanarak doldur - Ã¶nce ileri sonra geri doldurma
                for col in ['Open', 'High', 'Low', 'Close']:
                    if data[col].isnull().any():
                        # Ã–nce forward fill - Ã¶nceki deÄŸerle doldur
                        data[col] = data[col].fillna(method='ffill')
                        
                        # Sonra backward fill - sonraki deÄŸerle doldur
                        data[col] = data[col].fillna(method='bfill')
                        
                        # Hala eksik varsa interpolasyon kullan
                        data[col] = data[col].interpolate(method='linear')
                
                # Hacim iÃ§in sÄ±fÄ±r olmayan son deÄŸerle doldur
                if 'Volume' in data.columns and data['Volume'].isnull().any():
                    # Son sÄ±fÄ±r olmayan deÄŸerle doldur
                    data['Volume'] = data['Volume'].replace(0, np.nan).fillna(method='ffill')
                    # Kalan NaN'larÄ± medyan ile doldur
                    median_volume = data['Volume'].median()
                    data['Volume'] = data['Volume'].fillna(median_volume)
            
            # GERÃ‡EK ZAMANLI FÄ°YAT KONTROLÃœ EKLENDÄ° - HÄ°SSE KAPANIÅ FÄ°YATINI GÃœNCELLE
            try:
                # Ä°lk Ã¶nce fast_info ile dene (daha hÄ±zlÄ±)
                try:
                    fast_info = stock.fast_info
                    if hasattr(fast_info, 'last_price') and fast_info.last_price is not None:
                        current_market_price = fast_info.last_price
                        if 'log_expander' in globals() and log_expander is not None:
                            with log_expander:
                                st.success(f"----->>> [{symbol}] iÃ§in anlÄ±k fiyat (fast_info): {current_market_price}")
                        # En son veri noktasÄ±nÄ±n Close deÄŸerini gÃ¼ncelle
                        data.loc[data.index[-1], 'Close'] = current_market_price
                    else:
                        raise Exception("fast_info kullanÄ±lamadÄ±")
                except:
                    # fast_info Ã§alÄ±ÅŸmazsa info ile dene
                    info = stock.info
                    current_price_keys = ['regularMarketPrice', 'currentPrice', 'previousClose', 'ask', 'bid']
                    current_market_price = None
                    
                    for key in current_price_keys:
                        if key in info and info[key] is not None and info[key] > 0:
                            current_market_price = info[key]
                            if 'log_expander' in globals() and log_expander is not None:
                                with log_expander:
                                    st.success(f"----->>> [{symbol}] iÃ§in anlÄ±k fiyat ({key}): {current_market_price}")
                            break
                    
                    if current_market_price:
                        # En son veri noktasÄ±nÄ±n Close deÄŸerini gÃ¼ncelle
                        data.loc[data.index[-1], 'Close'] = current_market_price
                        # High ve Low deÄŸerlerini de kontrol et
                        last_high = data.loc[data.index[-1], 'High']
                        last_low = data.loc[data.index[-1], 'Low']
                        
                        # Current price, high'tan bÃ¼yÃ¼kse high'Ä± gÃ¼ncelle
                        if current_market_price > last_high:
                            data.loc[data.index[-1], 'High'] = current_market_price
                        
                        # Current price, low'dan kÃ¼Ã§Ã¼kse low'Ä± gÃ¼ncelle
                        if current_market_price < last_low:
                            data.loc[data.index[-1], 'Low'] = current_market_price
                    else:
                        if 'log_expander' in globals() and log_expander is not None:
                            with log_expander:
                                st.warning(f"----->>> [{symbol}] iÃ§in anlÄ±k fiyat hiÃ§bir key'de bulunamadÄ±")
                        
            except Exception as price_e:
                if 'log_expander' in globals() and log_expander is not None:
                    with log_expander:
                        st.warning(f"----->>> [{symbol}] anlÄ±k fiyat alÄ±namadÄ±: {str(price_e)}")
            
            return data
            
        except Exception as e:
            # Hata durumunu sadece log_expander varsa logla
            if 'log_expander' in globals() and log_expander is not None:
                with log_expander:
                    st.error(f"----->>> [{symbol}] yfinance veri alÄ±rken HATA: {str(e)}")
            return None

    # Teknik gÃ¶stergeleri hesaplayan fonksiyon
    def calculate_technical_indicators(data):
        """Temel teknik gÃ¶stergeleri hesaplar"""
        df = data.copy()
        
        # RSI
        delta = df['Close'].diff()
        gain = delta.where(delta > 0, 0)
        loss = -delta.where(delta < 0, 0)
        avg_gain = gain.rolling(window=14).mean()
        avg_loss = loss.rolling(window=14).mean()
        rs = avg_gain / avg_loss
        df['RSI'] = 100 - (100 / (1 + rs))
        
        # MACD
        df['MA_12'] = df['Close'].rolling(window=12).mean()
        df['MA_26'] = df['Close'].rolling(window=26).mean()
        df['MACD'] = df['MA_12'] - df['MA_26']
        df['MACD_Signal'] = df['MACD'].rolling(window=9).mean()
        df['MACD_Histogram'] = df['MACD'] - df['MACD_Signal']
        
        # Bollinger Bands
        df['MA_20'] = df['Close'].rolling(window=20).mean()
        df['20d_std'] = df['Close'].rolling(window=20).std()
        df['BB_Upper'] = df['MA_20'] + (df['20d_std'] * 2)
        df['BB_Lower'] = df['MA_20'] - (df['20d_std'] * 2)
        df['BB_Width'] = (df['BB_Upper'] - df['BB_Lower']) / df['MA_20']
        
        # Hareketli Ortalamalar
        df['MA_5'] = df['Close'].rolling(window=5).mean()
        df['MA_10'] = df['Close'].rolling(window=10).mean()
        df['MA_50'] = df['Close'].rolling(window=50).mean()
        df['MA_200'] = df['Close'].rolling(window=200).mean()
        
        # Hacim GÃ¶stergeleri
        df['Volume_Change'] = df['Volume'].pct_change()
        df['Volume_MA_20'] = df['Volume'].rolling(window=20).mean()
        df['Volume_Ratio'] = df['Volume'] / df['Volume_MA_20']
        
        # Momentum GÃ¶stergeleri
        df['Momentum_5'] = df['Close'] / df['Close'].shift(5)
        df['Momentum_10'] = df['Close'] / df['Close'].shift(10)
        df['ROC_5'] = df['Close'].pct_change(periods=5) * 100
        df['ROC_10'] = df['Close'].pct_change(periods=10) * 100
        
        # Stochastic Oscillator
        low_min = df['Low'].rolling(window=14).min()
        high_max = df['High'].rolling(window=14).max()
        df['Stoch_K'] = 100 * ((df['Close'] - low_min) / (high_max - low_min))
        df['Stoch_D'] = df['Stoch_K'].rolling(window=3).mean()
        
        # ATR (Average True Range)
        df['TR'] = np.maximum(
            np.maximum(
                df['High'] - df['Low'],
                abs(df['High'] - df['Close'].shift(1))
            ),
            abs(df['Low'] - df['Close'].shift(1))
        )
        df['ATR'] = df['TR'].rolling(window=14).mean()
        
        # OBV (On-Balance Volume)
        df['OBV'] = (np.sign(df['Close'].diff()) * df['Volume']).fillna(0).cumsum()
        
        # Getiri OranlarÄ±
        df['Daily_Return'] = df['Close'].pct_change()
        df['Weekly_Return'] = df['Close'].pct_change(5)
        df['Monthly_Return'] = df['Close'].pct_change(20)
        
        # Volatilite
        df['Volatility_5'] = df['Daily_Return'].rolling(window=5).std()
        df['Volatility_20'] = df['Daily_Return'].rolling(window=20).std()
        
        # Kanal GÃ¶stergeleri
        df['Upper_Channel'] = df['High'].rolling(window=20).max()
        df['Lower_Channel'] = df['Low'].rolling(window=20).min()
        df['Channel_Width'] = (df['Upper_Channel'] - df['Lower_Channel']) / df['MA_20']
        
        # EÄŸim GÃ¶stergeleri
        df['MA_5_Slope'] = df['MA_5'].diff(5) / 5
        df['MA_20_Slope'] = df['MA_20'].diff(5) / 5
        df['MA_50_Slope'] = df['MA_50'].diff(5) / 5
        
        # YENÄ°: Fibonacci Retracement Seviyeleri
        try:
            # Son 100 gÃ¼n iÃ§in pivotlar
            lookback = min(len(df), 100)
            if lookback >= 20:  # En az 20 veri noktasÄ± gerekli
                recent_df = df.iloc[-lookback:]
                
                # YÃ¼ksek ve dÃ¼ÅŸÃ¼k noktalarÄ± belirle
                recent_high = recent_df['High'].max()
                recent_low = recent_df['Low'].min()
                high_idx = recent_df['High'].idxmax()
                low_idx = recent_df['Low'].idxmin()
                
                # Trend yÃ¶nÃ¼nÃ¼ belirle (yÃ¼ksek nokta daha sonraysa yÃ¼kselen trend, tersi dÃ¼ÅŸen)
                uptrend = high_idx > low_idx
                
                # Fibonacci seviyeleri (yukarÄ± trend iÃ§in)
                if uptrend:
                    df['Fib_0'] = recent_low
                    df['Fib_23.6'] = recent_low + (recent_high - recent_low) * 0.236
                    df['Fib_38.2'] = recent_low + (recent_high - recent_low) * 0.382
                    df['Fib_50'] = recent_low + (recent_high - recent_low) * 0.5
                    df['Fib_61.8'] = recent_low + (recent_high - recent_low) * 0.618
                    df['Fib_100'] = recent_high
                    df['Fib_161.8'] = recent_low + (recent_high - recent_low) * 1.618
                else:  # AÅŸaÄŸÄ± trend iÃ§in
                    df['Fib_0'] = recent_high
                    df['Fib_23.6'] = recent_high - (recent_high - recent_low) * 0.236
                    df['Fib_38.2'] = recent_high - (recent_high - recent_low) * 0.382
                    df['Fib_50'] = recent_high - (recent_high - recent_low) * 0.5
                    df['Fib_61.8'] = recent_high - (recent_high - recent_low) * 0.618
                    df['Fib_100'] = recent_low
                    df['Fib_161.8'] = recent_high - (recent_high - recent_low) * 1.618
                
                # Fibonacci Trend Ä°liÅŸkisi
                df['Fib_Trend'] = 1 if uptrend else -1
                df['Price_To_Fib50'] = (df['Close'] - df['Fib_50']) / df['Fib_50']
                df['Price_To_Fib618'] = (df['Close'] - df['Fib_61.8']) / df['Fib_61.8']
        except Exception as e:
            # Hata olursa varsayÄ±lan deÄŸerler
            df['Fib_Trend'] = 0
            df['Price_To_Fib50'] = 0
            df['Price_To_Fib618'] = 0
        
        # YENÄ°: ZigZag ve OlasÄ± Elliott DalgalarÄ±
        try:
            # ZigZag parametreleri
            deviation_pct = 0.05  # Fiyat sapmasÄ± yÃ¼zdesi
            
            # ZigZag hesaplama
            # ZigZag, yÃ¶nÃ¼ deÄŸiÅŸtiren "Ã¶nemli" tepe ve dip noktalarÄ±nÄ± birleÅŸtiren Ã§izgiler oluÅŸturur
            high_series = df['High'].values
            low_series = df['Low'].values
            trend = 1  # 1: yukarÄ±, -1: aÅŸaÄŸÄ±
            zigzag_points = []
            
            # Ä°lk nokta iÃ§in baÅŸlangÄ±Ã§ deÄŸeri
            if len(high_series) > 0:
                current_point = {'date_idx': 0, 'price': low_series[0], 'type': 'low'}
                zigzag_points.append(current_point)
            
            # ZigZag noktalarÄ± bul
            for i in range(1, len(high_series)):
                # YukarÄ± trend
                if trend == 1:
                    # Yeni yÃ¼ksek nokta ara
                    if high_series[i] > current_point['price']:
                        current_point = {'date_idx': i, 'price': high_series[i], 'type': 'high'}
                        
                    # Ã–nceki yÃ¼ksekten Ã¶nemli bir dÃ¼ÅŸÃ¼ÅŸ mÃ¼ var?
                    elif low_series[i] < current_point['price'] * (1 - deviation_pct):
                        zigzag_points.append(current_point)  # Ã–nceki yÃ¼ksek noktayÄ± kaydet
                        current_point = {'date_idx': i, 'price': low_series[i], 'type': 'low'}
                        trend = -1  # Trend deÄŸiÅŸimi
                
                # AÅŸaÄŸÄ± trend
                else:
                    # Yeni dÃ¼ÅŸÃ¼k nokta ara
                    if low_series[i] < current_point['price']:
                        current_point = {'date_idx': i, 'price': low_series[i], 'type': 'low'}
                        
                    # Ã–nceki dÃ¼ÅŸÃ¼kten Ã¶nemli bir yÃ¼kseliÅŸ mi var?
                    elif high_series[i] > current_point['price'] * (1 + deviation_pct):
                        zigzag_points.append(current_point)  # Ã–nceki dÃ¼ÅŸÃ¼k noktayÄ± kaydet
                        current_point = {'date_idx': i, 'price': high_series[i], 'type': 'high'}
                        trend = 1  # Trend deÄŸiÅŸimi
            
            # Son noktayÄ± ekle
            zigzag_points.append(current_point)
            
            # ZigZag paternlerini analiz et
            
            # En az 5 ZigZag noktasÄ± gereklidir (Elliott dalgasÄ±nÄ±n minimum bÃ¶lÃ¼mÃ¼)
            if len(zigzag_points) >= 5:
                # Son 5 zigzag noktasÄ±nÄ± al (Elliott Ä°mpÃ¼lsif DalgasÄ± iÃ§in)
                last_zz_points = zigzag_points[-5:]
                
                # Basit Elliott Dalga Analizi (5 noktalÄ± impulsif dalga)
                is_impulse = True
                # Ä°mpÃ¼lsif dalga tipik deseni: yukarÄ±, aÅŸaÄŸÄ±, yukarÄ±, aÅŸaÄŸÄ±, yukarÄ± 
                # veya bunun tam tersi
                expected_types = ['low', 'high', 'low', 'high', 'low']  # YÃ¼kselen piyasa iÃ§in
                if last_zz_points[0]['type'] == 'high':
                    expected_types = ['high', 'low', 'high', 'low', 'high']  # DÃ¼ÅŸen piyasa iÃ§in
                
                # Nokta tiplerinin beklenen deseni takip edip etmediÄŸini kontrol et
                for i, point in enumerate(last_zz_points):
                    if point['type'] != expected_types[i]:
                        is_impulse = False
                        break
                
                # Elliott dalga durumunu kaydet
                df['Elliott_Impulse'] = 1 if is_impulse else 0
                
                # Elliott dalgasÄ±ndaki konum - 0 ila 1 arasÄ± normalleÅŸtirilmiÅŸ deÄŸer
                # 0 = baÅŸlangÄ±Ã§tayÄ±z, 1 = Elliott dalgasÄ±nÄ±n sonundayÄ±z
                if is_impulse:
                    total_points = len(last_zz_points)
                    # Son noktanÄ±n tarihi ile ilk noktanÄ±n tarihi arasÄ±nda kaÃ§ veri noktasÄ± var?
                    wave_length = last_zz_points[-1]['date_idx'] - last_zz_points[0]['date_idx']
                    
                    # Åu anki konumumuz
                    current_pos = df.index[-1] - last_zz_points[0]['date_idx']
                    
                    # Dalga iÃ§indeki konum - 0 ile 1 arasÄ±nda
                    if wave_length > 0:
                        df['Elliott_Position'] = min(1.0, max(0.0, current_pos / wave_length))
                    else:
                        df['Elliott_Position'] = 0
                else:
                    df['Elliott_Position'] = 0
                
                # Son ZigZag yÃ¶nÃ¼ (1=yukarÄ±, -1=aÅŸaÄŸÄ±)
                last_direction = 1 if last_zz_points[-1]['type'] == 'high' else -1
                df['ZigZag_Direction'] = last_direction
            else:
                # Yeterli ZigZag noktasÄ± yok
                df['Elliott_Impulse'] = 0
                df['Elliott_Position'] = 0
                df['ZigZag_Direction'] = 0
        except Exception as e:
            # Hata olursa varsayÄ±lan deÄŸerler
            df['Elliott_Impulse'] = 0
            df['Elliott_Position'] = 0
            df['ZigZag_Direction'] = 0
        
        return df

    def calculate_advanced_indicators(data):
        """GeliÅŸmiÅŸ teknik gÃ¶stergeleri hesaplar"""
        try:
            # Orijinal veriyi kopyala
            df = data.copy()
            
            # 1. Volume Oscillator: Hacim hareketlerinin yÃ¶nÃ¼nÃ¼ belirlemek iÃ§in kullanÄ±lÄ±r
            try:
                # KÄ±sa dÃ¶nem hacim ortalamasÄ± (5 gÃ¼n)
                df['volume_5d'] = df['Volume'].rolling(window=5).mean()
                
                # Uzun dÃ¶nem hacim ortalamasÄ± (20 gÃ¼n)
                df['volume_20d'] = df['Volume'].rolling(window=20).mean()
                
                # Hacim OsilatÃ¶rÃ¼: KÄ±sa dÃ¶nem - Uzun dÃ¶nem
                df['volume_oscillator'] = ((df['volume_5d'] - df['volume_20d']) / df['volume_20d']) * 100
                
                # Log mesajÄ±nÄ± sadece iÅŸlem gÃ¼nlÃ¼ÄŸÃ¼ne yaz
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("Hacim osilatÃ¶rÃ¼ baÅŸarÄ±yla hesaplandÄ±")
            except Exception as e:
                # Hata durumunda log'a kaydet ama UI'da gÃ¶sterme
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"Hacim osilatÃ¶rÃ¼ hesaplanÄ±rken hata: {str(e)}")
                df['volume_oscillator'] = 0
                
            # 2. Ichimoku Cloud gÃ¶stergeleri
            try:
                # Tenkan-sen (Conversion Line): (9 gÃ¼nlÃ¼k yÃ¼ksek + 9 gÃ¼nlÃ¼k dÃ¼ÅŸÃ¼k) / 2
                high_9 = df['High'].rolling(window=9).max()
                low_9 = df['Low'].rolling(window=9).min()
                df['Tenkan_sen'] = (high_9 + low_9) / 2
                
                # Kijun-sen (Base Line): (26 gÃ¼nlÃ¼k yÃ¼ksek + 26 gÃ¼nlÃ¼k dÃ¼ÅŸÃ¼k) / 2
                high_26 = df['High'].rolling(window=26).max()
                low_26 = df['Low'].rolling(window=26).min()
                df['Kijun_sen'] = (high_26 + low_26) / 2
                
                # Senkou Span A (Leading Span A): (Tenkan-sen + Kijun-sen) / 2
                df['Senkou_span_A'] = ((df['Tenkan_sen'] + df['Kijun_sen']) / 2).shift(26)
                
                # Senkou Span B (Leading Span B): (52 gÃ¼nlÃ¼k yÃ¼ksek + 52 gÃ¼nlÃ¼k dÃ¼ÅŸÃ¼k) / 2
                high_52 = df['High'].rolling(window=52).max()
                low_52 = df['Low'].rolling(window=52).min()
                df['Senkou_span_B'] = ((high_52 + low_52) / 2).shift(26)
                
                # Chikou Span (Lagging Span): KapanÄ±ÅŸ 26 gÃ¼n geriye kaydÄ±rÄ±lÄ±r
                df['Chikou_span'] = df['Close'].shift(-26)
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("Ichimoku Cloud gÃ¶stergeleri baÅŸarÄ±yla hesaplandÄ±")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"Ichimoku Cloud gÃ¶stergeleri hesaplanÄ±rken hata: {str(e)}")
            
            # 3. Chaikin Money Flow (CMF)
            try:
                n = 20  # Periyot
                mfv = ((df['Close'] - df['Low']) - (df['High'] - df['Close'])) / (df['High'] - df['Low'])
                mfv = mfv.fillna(0.0)  # BÃ¶lme hatasÄ± olasÄ±lÄ±ÄŸÄ±na karÅŸÄ±
                mfv *= df['Volume']
                df['CMF'] = mfv.rolling(n).sum() / df['Volume'].rolling(n).sum()
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("CMF gÃ¶stergesi baÅŸarÄ±yla hesaplandÄ±")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"CMF gÃ¶stergesi hesaplanÄ±rken hata: {str(e)}")
                df['CMF'] = 0
            
            # 4. Williams %R
            try:
                n = 14  # Periyot
                high_max = df['High'].rolling(window=n).max()
                low_min = df['Low'].rolling(window=n).min()
                df['Williams_%R'] = -100 * ((high_max - df['Close']) / (high_max - low_min))
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("Williams %R gÃ¶stergesi baÅŸarÄ±yla hesaplandÄ±")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"Williams %R gÃ¶stergesi hesaplanÄ±rken hata: {str(e)}")
                df['Williams_%R'] = 0
            
            # 5. Commodity Channel Index (CCI)
            try:
                n = 20  # Periyot
                typical_price = (df['High'] + df['Low'] + df['Close']) / 3
                mean_typical_price = typical_price.rolling(window=n).mean()
                mean_deviation = np.zeros(len(df))
                
                for i in range(n - 1, len(df)):
                    mean_deviation[i] = np.mean(np.abs(typical_price.iloc[i-n+1:i+1] - mean_typical_price.iloc[i]))
                
                df['CCI'] = (typical_price - mean_typical_price) / (0.015 * pd.Series(mean_deviation))
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("CCI gÃ¶stergesi baÅŸarÄ±yla hesaplandÄ±")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"CCI gÃ¶stergesi hesaplanÄ±rken hata: {str(e)}")
                df['CCI'] = 0
            
            # 6. Aroon Oscillator
            try:
                n = 25  # Periyot
                
                # Aroon Up
                aroon_up = np.zeros(len(df))
                for i in range(n, len(df)):
                    period = df['High'].iloc[i-n+1:i+1]
                    aroon_up[i] = ((n - period.argmax() - 1) / n) * 100
                
                # Aroon Down
                aroon_down = np.zeros(len(df))
                for i in range(n, len(df)):
                    period = df['Low'].iloc[i-n+1:i+1]
                    aroon_down[i] = ((n - period.argmin() - 1) / n) * 100
                
                df['Aroon_Up'] = pd.Series(aroon_up)
                df['Aroon_Down'] = pd.Series(aroon_down)
                df['Aroon_Oscillator'] = df['Aroon_Up'] - df['Aroon_Down']
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("Aroon Oscillator baÅŸarÄ±yla hesaplandÄ±")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"Aroon Oscillator hesaplanÄ±rken hata: {str(e)}")
                df['Aroon_Oscillator'] = 0
            
            # 7. Keltner Channels
            try:
                n = 20  # Periyot
                k = 2  # Ã‡arpan
                
                df['EMA20'] = df['Close'].ewm(span=n, adjust=False).mean()
                
                # EÄŸer TR hesaplanmamÄ±ÅŸsa hesaplama yapalÄ±m
                if 'TR' not in df.columns:
                    df['TR'] = np.maximum(
                        np.maximum(
                            df['High'] - df['Low'],
                            abs(df['High'] - df['Close'].shift(1))
                        ),
                        abs(df['Low'] - df['Close'].shift(1))
                    )
                
                atr = df['TR'].rolling(window=n).mean()  # ATR hesapla
                
                df['Keltner_Upper'] = df['EMA20'] + (k * atr)
                df['Keltner_Lower'] = df['EMA20'] - (k * atr)
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("Keltner Channels baÅŸarÄ±yla hesaplandÄ±")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"Keltner Channels hesaplanÄ±rken hata: {str(e)}")
                # Hata durumunda kolonlarÄ± ekle
                df['Keltner_Upper'] = df['Close'] 
                df['Keltner_Lower'] = df['Close']
            
            # 8. Donchian Channels
            try:
                n = 20  # Periyot
                df['Donchian_Upper'] = df['High'].rolling(window=n).max()
                df['Donchian_Lower'] = df['Low'].rolling(window=n).min()
                df['Donchian_Middle'] = (df['Donchian_Upper'] + df['Donchian_Lower']) / 2
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("Donchian Channels baÅŸarÄ±yla hesaplandÄ±")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"Donchian Channels hesaplanÄ±rken hata: {str(e)}")
            
            # 9. Parabolic SAR (Stop and Reverse)
            try:
                # BasitleÅŸtirilmiÅŸ bir PSAR hesaplamasÄ±
                acceleration_factor = 0.02
                max_acceleration = 0.2
                sar = np.zeros(len(df))
                trend = np.zeros(len(df))
                ep = np.zeros(len(df))
                
                # Ä°lk deÄŸerleri ayarla
                if len(df) > 1:
                    if df['Close'].iloc[1] > df['Close'].iloc[0]:
                        trend[1] = 1  # YukarÄ± trend
                        sar[1] = df['Low'].iloc[0]
                        ep[1] = df['High'].iloc[1]
                    else:
                        trend[1] = -1  # AÅŸaÄŸÄ± trend
                        sar[1] = df['High'].iloc[0]
                        ep[1] = df['Low'].iloc[1]
                
                # PSAR hesapla
                for i in range(2, len(df)):
                    if trend[i-1] == 1:  # YukarÄ± trend
                        if df['Low'].iloc[i] < sar[i-1]:
                            trend[i] = -1  # Trend deÄŸiÅŸimi
                            sar[i] = ep[i-1]
                            ep[i] = df['Low'].iloc[i]
                            acceleration = acceleration_factor
                        else:
                            trend[i] = 1
                            if df['High'].iloc[i] > ep[i-1]:
                                ep[i] = df['High'].iloc[i]
                                acceleration = min(acceleration_factor + acceleration_factor, max_acceleration)
                            else:
                                ep[i] = ep[i-1]
                                acceleration = acceleration_factor
                            sar[i] = sar[i-1] + acceleration * (ep[i-1] - sar[i-1])
                            sar[i] = min(sar[i], df['Low'].iloc[i-1], df['Low'].iloc[i-2] if i > 2 else df['Low'].iloc[i-1])
                    else:  # AÅŸaÄŸÄ± trend
                        if df['High'].iloc[i] > sar[i-1]:
                            trend[i] = 1  # Trend deÄŸiÅŸimi
                            sar[i] = ep[i-1]
                            ep[i] = df['High'].iloc[i]
                            acceleration = acceleration_factor
                        else:
                            trend[i] = -1
                            if df['Low'].iloc[i] < ep[i-1]:
                                ep[i] = df['Low'].iloc[i]
                                acceleration = min(acceleration_factor + acceleration_factor, max_acceleration)
                            else:
                                ep[i] = ep[i-1]
                                acceleration = acceleration_factor
                            sar[i] = sar[i-1] + acceleration * (ep[i-1] - sar[i-1])
                            sar[i] = max(sar[i], df['High'].iloc[i-1], df['High'].iloc[i-2] if i > 2 else df['High'].iloc[i-1])
                
                df['SAR'] = pd.Series(sar)
                df['SAR_Trend'] = pd.Series(trend)
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("Parabolic SAR gÃ¶stergesi baÅŸarÄ±yla hesaplandÄ±")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"Parabolic SAR gÃ¶stergesi hesaplanÄ±rken hata: {str(e)}")
                df['SAR'] = 0
                df['SAR_Trend'] = 0
            
            # 10. Vortex Indicator
            try:
                n = 14  # Periyot
                
                # EÄŸer TR hesaplanmamÄ±ÅŸsa hesaplama yapalÄ±m
                if 'TR' not in df.columns:
                    df['TR'] = np.maximum(
                        np.maximum(
                            df['High'] - df['Low'],
                            abs(df['High'] - df['Close'].shift(1))
                        ),
                        abs(df['Low'] - df['Close'].shift(1))
                    )
                
                # Pozitif ve Negatif Hareket
                df['VM_plus'] = abs(df['High'] - df['Low'].shift(1))
                df['VM_minus'] = abs(df['Low'] - df['High'].shift(1))
                
                # Vortex GÃ¶stergesi
                df['VI_plus'] = df['VM_plus'].rolling(n).sum() / df['TR'].rolling(n).sum()
                df['VI_minus'] = df['VM_minus'].rolling(n).sum() / df['TR'].rolling(n).sum()
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("Vortex Indicator baÅŸarÄ±yla hesaplandÄ±")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"Vortex Indicator hesaplanÄ±rken hata: {str(e)}")
                df['VI_plus'] = 0
                df['VI_minus'] = 0
            
            # 11. TRIX Indicator (Triple Exponential Moving Average)
            try:
                n = 15  # Periyot
                
                ema1 = df['Close'].ewm(span=n, adjust=False).mean()
                ema2 = ema1.ewm(span=n, adjust=False).mean()
                ema3 = ema2.ewm(span=n, adjust=False).mean()
                df['TRIX'] = 100 * (ema3 - ema3.shift(1)) / ema3.shift(1)
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("TRIX Indicator baÅŸarÄ±yla hesaplandÄ±")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"TRIX Indicator hesaplanÄ±rken hata: {str(e)}")
                df['TRIX'] = 0
            
            # 12. DPO (Detrended Price Oscillator)
            try:
                n = 20  # Periyot
                df['DPO'] = df['Close'].shift(n//2 + 1) - df['Close'].rolling(window=n).mean()
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("DPO gÃ¶stergesi baÅŸarÄ±yla hesaplandÄ±")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"DPO gÃ¶stergesi hesaplanÄ±rken hata: {str(e)}")
                df['DPO'] = 0
            
            # 13. CMO (Chande Momentum Oscillator)
            try:
                n = 14  # Periyot
                
                close_change = df['Close'].diff()
                up_sum = close_change.where(close_change > 0, 0).rolling(window=n).sum()
                down_sum = -close_change.where(close_change < 0, 0).rolling(window=n).sum()
                
                df['CMO'] = 100 * ((up_sum - down_sum) / (up_sum + down_sum))
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("CMO gÃ¶stergesi baÅŸarÄ±yla hesaplandÄ±")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"CMO gÃ¶stergesi hesaplanÄ±rken hata: {str(e)}")
                df['CMO'] = 0
            
            # 14. PVT (Price Volume Trend)
            try:
                close_change_pct = df['Close'].pct_change()
                df['PVT'] = (close_change_pct * df['Volume']).cumsum()
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("PVT gÃ¶stergesi baÅŸarÄ±yla hesaplandÄ±")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"PVT gÃ¶stergesi hesaplanÄ±rken hata: {str(e)}")
                df['PVT'] = 0
            
            # 15. Fiyat-Hacim ve Volatilite Ä°liÅŸki Metrikleri
            try:
                # Fiyat-Hacim korelasyonu (20 gÃ¼n)
                n = 20
                df['Price_Volume_Corr'] = df['Close'].rolling(window=n).corr(df['Volume'])
                
                # Fiyat volatilitesi (20 gÃ¼n)
                df['Price_Volatility'] = df['Close'].pct_change().rolling(window=n).std() * np.sqrt(n)
                
                # Hacim volatilitesi (20 gÃ¼n)
                df['Volume_Volatility'] = df['Volume'].pct_change().rolling(window=n).std() * np.sqrt(n)
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("Fiyat-Hacim iliÅŸki metrikleri baÅŸarÄ±yla hesaplandÄ±")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"Fiyat-Hacim iliÅŸki metrikleri hesaplanÄ±rken hata: {str(e)}")
                df['Price_Volume_Corr'] = 0
                df['Price_Volatility'] = 0
                df['Volume_Volatility'] = 0
            
            # 16. Fibonacci Retracement Seviyeleri
            try:
                # Son 50 gÃ¼n iÃ§in yÃ¼ksek ve dÃ¼ÅŸÃ¼k noktalarÄ± bul
                period = 50
                if len(df) >= period:
                    recent_high = df['High'].iloc[-period:].max()
                    recent_low = df['Low'].iloc[-period:].min()
                    
                    # Fibonacci seviyeleri
                    df['Fib_38.2'] = recent_high - (recent_high - recent_low) * 0.382
                    df['Fib_50'] = recent_high - (recent_high - recent_low) * 0.5
                    df['Fib_61.8'] = recent_high - (recent_high - recent_low) * 0.618
                    
                    if 'log_expander' in globals():
                        with log_expander:
                            st.info("Fibonacci Retracement seviyeleri baÅŸarÄ±yla hesaplandÄ±")
                else:
                    df['Fib_38.2'] = df['Close']
                    df['Fib_50'] = df['Close']
                    df['Fib_61.8'] = df['Close']
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"Fibonacci Retracement seviyeleri hesaplanÄ±rken hata: {str(e)}")
                df['Fib_38.2'] = 0
                df['Fib_50'] = 0
                df['Fib_61.8'] = 0
            
            # NaN deÄŸerleri temizle veya doldur
            for col in df.columns:
                if col not in data.columns and col in df.columns:
                    if df[col].isnull().any():
                        df[col] = df[col].fillna(0)
            
            return df

        except Exception as e:
            if 'log_expander' in globals():
                with log_expander:
                    st.error(f"GeliÅŸmiÅŸ teknik gÃ¶stergeler hesaplanÄ±rken genel hata: {str(e)}")
            return data

    def add_sentiment_data(df, symbol):
        """ Hisse senedi verilerine duyarlÄ±lÄ±k analizi sonuÃ§larÄ±nÄ± ekler """
        if not use_sentiment_analysis:
            df['Gemini_Sentiment'] = 0.0 
            return df, True  # DuyarlÄ±lÄ±k analizi kullanÄ±lmadÄ±ÄŸÄ±nda bile baÅŸarÄ±yla eklenmiÅŸ olarak iÅŸaretliyoruz
            
        with log_expander:
            st.info(f"--> [{symbol}] DuyarlÄ±lÄ±k Analizi BaÅŸlatÄ±lÄ±yor...")
            st.info(f"----> [{symbol}] Haber verileri alÄ±nÄ±yor...")
        
        sentiment_added_successfully = False
        df['Gemini_Sentiment'] = np.nan 

        try:
            # Haber verilerini al
            try:
                # Haber alÄ±nÄ±rken oluÅŸan detaylÄ± loglarÄ± log_expander iÃ§inde tut
                news_capture = io.StringIO()
                with redirect_stdout(news_capture):
                    news_items_list = get_stock_news(symbol, news_period="1w", max_results=5)
                
                # Haber alÄ±nÄ±rken oluÅŸan detaylÄ± loglarÄ± sadece log_expander iÃ§inde gÃ¶ster
                news_logs = news_capture.getvalue()
                if news_logs.strip():
                    with log_expander:
                        st.text(news_logs)
                
                with log_expander:
                    if news_items_list:
                        st.success(f"----> [{symbol}] {len(news_items_list)} adet haber bulundu.")
                    else:
                        st.warning(f"----> [{symbol}] Haber bulunamadÄ±.")
            except Exception as news_e:
                with log_expander:
                    st.error(f"----> [{symbol}] Haber alÄ±nÄ±rken hata: {str(news_e)}")
                news_items_list = []

            # VarsayÄ±lan nÃ¶tr skor
            sentiment_skoru = 50 

            if news_items_list:
                # Haberleri analiz et
                sentiments = []
                
                with log_expander:
                    st.info(f"----> [{symbol}] Haberler analiz ediliyor...")
                
                # FarklÄ± analiz yÃ¶ntemlerini deneme sayaÃ§larÄ±
                successful_analyses = 0
                failed_analyses = 0
                
                # Haberler modÃ¼lÃ¼nÃ¼ ve SentimentAnalyzer'Ä± yÃ¼kle
                try:
                    # Ä°lk olarak SentimentAnalyzer'Ä± yÃ¼klemeyi dene
                    from ai.sentiment_analysis import SentimentAnalyzer
                    sentiment_analyzer = SentimentAnalyzer()
                    sentiment_analyzer_available = True
                    with log_expander:
                        st.success(f"-----> Yedek analiz modeli baÅŸarÄ±yla yÃ¼klendi: {os.path.join(os.getcwd(), 'ai', 'sentiment_model.pkl')}")
                except Exception as sa_error:
                    sentiment_analyzer_available = False
                    with log_expander:
                        st.error(f"-----> Analiz modeli yÃ¼klenemedi: {str(sa_error)}")
                
                # Haberler modÃ¼lÃ¼nden fonksiyonlarÄ± import et
                try:
                    from ui.news_tab import (
                        analyze_news, 
                        get_sentiment_explanation, 
                        simple_sentiment_analysis
                    )
                    news_analyzer_available = True
                    with log_expander:
                        st.success(f"-----> Haberler modÃ¼lÃ¼ analiz fonksiyonu baÅŸarÄ±yla yÃ¼klendi")
                except Exception as news_tab_error:
                    news_analyzer_available = False
                    with log_expander:
                        st.error(f"-----> Haberler modÃ¼lÃ¼ analiz fonksiyonu yÃ¼klenemedi: {str(news_tab_error)}")
                
                # Her bir haberi analiz et
                for item in news_items_list:
                    try:
                        # URL kontrolÃ¼
                        item_url = item.get('url') or item.get('link')
                        if not item_url:
                            with log_expander:
                                st.warning(f"-----> GeÃ§erli URL bulunamadÄ±, atlanÄ±yor...")
                            continue
                            
                        with log_expander:
                            st.info(f"-----> Haber analiz ediliyor: {item.get('title', 'BaÅŸlÄ±k Yok')}")
                        
                        # BaÅŸlÄ±k ve iÃ§erik metnini hazÄ±rla - bunlar her durumda kullanÄ±lacak
                        title = item.get('title', '')
                        description = item.get('description', '') or item.get('summary', '') or item.get('desc', '')
                        analysis_text = f"{title} {description}"
                        
                        # YÃ¶ntem 1: Basit kelime tabanlÄ± analiz (her durumda Ã§alÄ±ÅŸacak)
                        sentiment_score = 0.5  # NÃ¶tr varsayÄ±lan deÄŸer
                        sentiment_label = "NÃ¶tr"
                        
                        if news_analyzer_available:
                            try:
                                # Finans haberlerine Ã¶zel geliÅŸmiÅŸ kelime tabanlÄ± analiz
                                # Olumlu ve olumsuz kelimeler
                                positive_words = [
                                    # Genel olumlu terimler
                                    "artÄ±ÅŸ", "yÃ¼kseldi", "yÃ¼kseliÅŸ", "kazanÃ§", "baÅŸarÄ±", "olumlu", "gÃ¼Ã§lÃ¼", 
                                    "kar", "bÃ¼yÃ¼me", "yatÄ±rÄ±m", "fÄ±rsat", "rekor", "gÃ¼ven", "avantaj",
                                    # Hisse senedi ve finans ile ilgili olumlu terimler
                                    "alÄ±m", "geri alÄ±m", "pay geri alÄ±m", "hedef fiyat", "yukarÄ± yÃ¶nlÃ¼", "artÄ±rÄ±ldÄ±", 
                                    "yÃ¼kseltildi", "ivme", "gÃ¼Ã§leniyor", "zirve", "tavan", "prim", "aÅŸÄ±rÄ± alÄ±m", 
                                    "gÃ¼Ã§lÃ¼ performans", "kÃ¢rlÄ±lÄ±k", "temettÃ¼", "beklentilerin Ã¼zerinde", "kapasite artÄ±ÅŸÄ±",
                                    "lider", "pazar payÄ±", "bÃ¼yÃ¼dÃ¼", "arttÄ±", "geniÅŸleme", "ihracat", "yeni anlaÅŸma",
                                    "ortaklÄ±k", "iÅŸbirliÄŸi", "strateji", "dijitalleÅŸme", "teknoloji", "dev", "program",
                                    "iÅŸ hacmi", "raÄŸbet", "talep", "ihale", "kazandÄ±", "baÅŸarÄ±yla", "gelir artÄ±ÅŸÄ±"
                                ]
                                
                                negative_words = [
                                    # Genel olumsuz terimler
                                    "dÃ¼ÅŸÃ¼ÅŸ", "geriledi", "azaldÄ±", "zarar", "kayÄ±p", "olumsuz", "zayÄ±f", 
                                    "risk", "endiÅŸe", "kriz", "tehlike", "yavaÅŸlama", "dezavantaj",
                                    # Hisse senedi ve finans ile ilgili olumsuz terimler
                                    "satÄ±ÅŸ baskÄ±sÄ±", "deÄŸer kaybÄ±", "daraldÄ±", "daralma", "borÃ§", "iflas", "konkordato",
                                    "aÅŸaÄŸÄ± yÃ¶nlÃ¼", "indirildi", "dÃ¼ÅŸÃ¼rÃ¼ldÃ¼", "aÅŸÄ±rÄ± satÄ±m", "volatilite", "zayÄ±f performans",
                                    "beklentilerin altÄ±nda", "ertelendi", "iptal", "durgunluk", "negatif", "dibe", "dip",
                                    "indirim", "faiz artÄ±ÅŸÄ±", "vergi", "ceza", "yaptÄ±rÄ±m", "manipÃ¼lasyon", "soruÅŸturma",
                                    "dava", "para cezasÄ±", "ÅŸikayet", "protesto", "grev", "maliyet artÄ±ÅŸÄ±", "fire"
                                ]
                                
                                # Metin Ã¶zel durumlarÄ± ele al - finans haberlerinde bazÄ± ifadeler Ã¶zel anlam taÅŸÄ±r
                                special_cases = [
                                    {"phrase": "pay geri alÄ±m", "score": 1.0},
                                    {"phrase": "hisse geri alÄ±m", "score": 1.0},
                                    {"phrase": "hedef fiyat", "score": 0.8},
                                    {"phrase": "tavan fiyat", "score": 0.7},
                                    {"phrase": "ek sefer", "score": 0.7},
                                    {"phrase": "yatÄ±rÄ±m tavsiyesi", "score": 0.6},
                                    {"phrase": "al tavsiyesi", "score": 0.9},
                                    {"phrase": "tut tavsiyesi", "score": 0.6},
                                    {"phrase": "sat tavsiyesi", "score": 0.2}
                                ]
                                
                                # Hisse Ã¶zel durumlarÄ± kontrol et
                                if symbol in analysis_text:
                                    with log_expander:
                                        st.info(f"-----> Hisse kodu ({symbol}) iÃ§erikte geÃ§iyor. FaydalÄ± bir haber olabilir.")
                                
                                # Ã–zel durumlarÄ± kontrol et
                                special_score = None
                                for case in special_cases:
                                    if case["phrase"].lower() in analysis_text.lower():
                                        special_score = case["score"]
                                        with log_expander:
                                            st.success(f"-----> Ã–zel durum tespit edildi: '{case['phrase']}', skor: {special_score}")
                                        break
                                
                                # EÄŸer Ã¶zel durum varsa, doÄŸrudan skoru ata
                                if special_score is not None:
                                    sentiment_score = special_score
                                    sentiment_label = "POSITIVE" if sentiment_score > 0.5 else ("NEUTRAL" if sentiment_score == 0.5 else "NEGATIVE")
                                else:
                                    # Kelime sayaÃ§larÄ±
                                    positive_count = sum(1 for word in positive_words if word.lower() in analysis_text.lower())
                                    negative_count = sum(1 for word in negative_words if word.lower() in analysis_text.lower())
                                    
                                    # Duygu skoru hesapla (0 ile 1 arasÄ±nda)
                                    total = positive_count + negative_count
                                    if total > 0:
                                        # Pozitif sayÄ±sÄ± aÄŸÄ±rlÄ±klÄ±ysa skoru yÃ¼kselt
                                        sentiment_score = positive_count / (positive_count + negative_count)
                                        with log_expander:
                                            st.info(f"-----> Olumlu kelime sayÄ±sÄ±: {positive_count}, Olumsuz kelime sayÄ±sÄ±: {negative_count}")
                                    else:
                                        sentiment_score = 0.5  # NÃ¶tr deÄŸer
                                    
                                    # Etiket belirle
                                    if sentiment_score > 0.6:
                                        sentiment_label = "POSITIVE"
                                    elif sentiment_score < 0.4:
                                        sentiment_label = "NEGATIVE"
                                    else:
                                        sentiment_label = "NEUTRAL"
                                
                                with log_expander:
                                    sentiment_text = "Olumlu" if sentiment_label == "POSITIVE" else ("Olumsuz" if sentiment_label == "NEGATIVE" else "NÃ¶tr")
                                    st.success(f"-----> GeliÅŸmiÅŸ kelime analizi sonucu: {sentiment_text} ({sentiment_score:.2f})")
                                
                                sentiments.append(sentiment_score)
                                successful_analyses += 1
                                continue
                            except Exception as advanced_analysis_error:
                                with log_expander:
                                    st.warning(f"-----> GeliÅŸmiÅŸ kelime analizi hatasÄ±: {str(advanced_analysis_error)}")
                                
                                # Hata durumunda basit kelime analizi ile devam et
                                try:
                                    # Basit kelime tabanlÄ± duyarlÄ±lÄ±k analizi
                                    simple_result = simple_sentiment_analysis(analysis_text)
                                    sentiment_score = simple_result.get("score", 0.5)
                                    sentiment_label = simple_result.get("label", "NEUTRAL")
                                    
                                    with log_expander:
                                        sentiment_text = "Olumlu" if sentiment_label == "POSITIVE" else ("Olumsuz" if sentiment_label == "NEGATIVE" else "NÃ¶tr")
                                        st.info(f"-----> Basit analiz sonucu: {sentiment_text} ({sentiment_score:.2f})")
                                    
                                    # Skorun 0-1 aralÄ±ÄŸÄ±nda olduÄŸundan emin ol
                                    if sentiment_score < 0:
                                        sentiment_score = 0
                                    elif sentiment_score > 1:
                                        sentiment_score = 1
                                        
                                    sentiments.append(sentiment_score)
                                    successful_analyses += 1
                                    continue
                                except Exception as simple_error:
                                    with log_expander:
                                        st.warning(f"-----> Basit analiz hatasÄ±: {str(simple_error)}")
                        
                        # YÃ¶ntem 2: SentimentAnalyzer kullan
                        if sentiment_analyzer_available:
                            try:
                                # Metni analiz et
                                with log_expander:
                                    st.info(f"-----> Scikit-learn modeli ile analiz ediliyor...")
                                
                                if analysis_text and len(analysis_text.strip()) > 10:
                                    # DuyarlÄ±lÄ±k skorunu hesapla
                                    prediction = sentiment_analyzer.predict([analysis_text])[0]
                                    probabilities = sentiment_analyzer.predict_proba([analysis_text])[0]
                                    
                                    # 0 (negatif) veya 1 (pozitif) - label'a dÃ¶nÃ¼ÅŸtÃ¼r
                                    label = "POSITIVE" if prediction == 1 else "NEGATIVE"
                                    
                                    # Skoru normalize et
                                    score = (probabilities[1] if len(probabilities) > 1 else 0.5)
                                    
                                    with log_expander:
                                        sentiment_text = "Olumlu" if score > 0.65 else ("Olumsuz" if score < 0.35 else "NÃ¶tr")
                                        st.success(f"-----> Scikit-learn analiz sonucu: {sentiment_text} ({score:.2f})")
                                        if 'get_sentiment_explanation' in locals():
                                            st.info(f"-----> {get_sentiment_explanation(score)}")
                                    
                                    sentiments.append(score)
                                    successful_analyses += 1
                                    continue
                                else:
                                    with log_expander:
                                        st.warning(f"-----> Analiz metni Ã§ok kÄ±sa, atlanÄ±yor...")
                            except Exception as model_error:
                                with log_expander:
                                    st.warning(f"-----> Scikit-learn model hatasÄ±: {str(model_error)}")
                        
                        # VarsayÄ±lan nÃ¶tr deÄŸer
                        with log_expander:
                            st.info(f"-----> BaÅŸarÄ±sÄ±z analizler iÃ§in varsayÄ±lan nÃ¶tr deÄŸer (0.5) kullanÄ±lÄ±yor...")
                        sentiments.append(0.5)
                        successful_analyses += 1
                        
                    except Exception as item_error:
                        failed_analyses += 1
                        with log_expander:
                            st.error(f"-----> Haber analiz etme hatasÄ±: {str(item_error)}")
                
                # Analiz edilmiÅŸ haber var mÄ±?
                if sentiments:
                    # BaÅŸarÄ±lÄ± ve baÅŸarÄ±sÄ±z analiz sayÄ±larÄ±nÄ± logla
                    with log_expander:
                        st.info(f"----> [{symbol}] Toplam {len(news_items_list)} haberden {successful_analyses} adedi baÅŸarÄ±yla analiz edildi, {failed_analyses} adedi baÅŸarÄ±sÄ±z.")
                    
                    # Ortalama duyarlÄ±lÄ±k skorunu hesapla
                    avg_sentiment = sum(sentiments) / len(sentiments)
                    
                    # 0-1 aralÄ±ÄŸÄ±ndaki skoru -1 ile 1 arasÄ±na dÃ¶nÃ¼ÅŸtÃ¼r
                    normalized_sentiment = (avg_sentiment - 0.5) * 2
                    
                    with log_expander:
                        sentiment_str = "Olumlu" if avg_sentiment > 0.65 else ("Olumsuz" if avg_sentiment < 0.35 else "NÃ¶tr")
                        st.success(f"----> [{symbol}] Ortalama DuyarlÄ±lÄ±k: {sentiment_str} ({avg_sentiment:.2f})")
                        st.info(f"----> [{symbol}] Normalize EdilmiÅŸ Skor: {normalized_sentiment:.2f}")
                    
                    # Son N gÃ¼ne skoru ata
                    n_days = 5
                    if len(df) >= n_days:
                        df.iloc[-n_days:, df.columns.get_loc('Gemini_Sentiment')] = normalized_sentiment
                    elif len(df) > 0:
                        df['Gemini_Sentiment'] = normalized_sentiment
                    
                    sentiment_added_successfully = True
                else:
                    with log_expander:
                        st.warning(f"----> [{symbol}] HiÃ§bir haber analiz edilemedi, nÃ¶tr skor kullanÄ±lÄ±yor.")
                    normalized_sentiment = 0.0
                    df['Gemini_Sentiment'] = normalized_sentiment
                    sentiment_added_successfully = True  # NÃ¶tr skor eklendiÄŸinde de baÅŸarÄ±lÄ± sayÄ±lsÄ±n
            else:
                with log_expander:
                    st.info(f"----> [{symbol}] Haber bulunmadÄ±ÄŸÄ± iÃ§in nÃ¶tr skor (0) kullanÄ±lÄ±yor.")
                normalized_sentiment = 0.0
                df['Gemini_Sentiment'] = normalized_sentiment
                sentiment_added_successfully = True  # Haber yoksa ve nÃ¶tr skor eklendiÄŸinde de baÅŸarÄ±lÄ± sayÄ±lsÄ±n

            # NaN deÄŸerleri doldur
            df['Gemini_Sentiment'].fillna(method='ffill', inplace=True)
            df['Gemini_Sentiment'].fillna(0, inplace=True)
            
            with log_expander:
                st.success(f"--> [{symbol}] DuyarlÄ±lÄ±k Analizi TamamlandÄ±.")
            return df, sentiment_added_successfully

        # Ana try bloÄŸu iÃ§in except bloÄŸu
        except Exception as e:
            with log_expander:
                st.error(f"--> [{symbol}] DuyarlÄ±lÄ±k analizi genel hatasÄ±: {str(e)}")
                st.code(traceback.format_exc())
            df['Gemini_Sentiment'] = 0.0
            return df, True  # Hata durumunda bile 0 deÄŸeri eklenmiÅŸ olduÄŸu iÃ§in True dÃ¶nelim

    # YENÄ°: Makroekonomik ve sektÃ¶rel veri ekleme fonksiyonu
    def add_macro_sector_data(df, symbol):
        """
        Makroekonomik gÃ¶stergeleri (dÃ¶viz, faiz, enflasyon) ve sektÃ¶rel korelasyonlarÄ± ekler
        
        Parametreler:
        df (DataFrame): Ä°ÅŸlenecek veri seti
        symbol (str): Hisse kodu
        
        DÃ¶nÃ¼ÅŸ:
        DataFrame: Makroekonomik ve sektÃ¶rel Ã¶zellikler eklenmiÅŸ veri seti
        """
        try:
            if 'log_expander' in globals() and log_expander is not None:
                with log_expander:
                    st.info(f"--> [{symbol}] Makroekonomik ve SektÃ¶rel veri ekleniyor...")
            
            # 1. Dolar/TL Kuru
            try:
                usdtry_data = get_stock_data_cached("USDTRY=X", period="5y", interval="1d")
                if usdtry_data is not None and not usdtry_data.empty:
                    # Tarih indekslerini eÅŸleÅŸtirme
                    common_idx = df.index.intersection(usdtry_data.index)
                    if len(common_idx) > 0:
                        usd_aligned = usdtry_data.loc[common_idx]['Close']
                        
                        # DÃ¶viz kuru deÄŸiÅŸim yÃ¼zdeleri
                        df['USDTRY'] = usd_aligned
                        df['USDTRY_Change'] = usd_aligned.pct_change()
                        df['USDTRY_Change_5d'] = usd_aligned.pct_change(5)
                        df['USDTRY_Change_20d'] = usd_aligned.pct_change(20)
                        
                        # Hisse/DÃ¶viz korelasyonu (20 gÃ¼nlÃ¼k)
                        rolling_corr = df['Close'].rolling(window=20).corr(df['USDTRY'])
                        df['USD_Correlation'] = rolling_corr
                        
                        # Pozitif korelasyon
                        df['Is_USD_Positive_Corr'] = np.where(rolling_corr > 0.5, 1, 0)
                        
                        # Negatif korelasyon
                        df['Is_USD_Negative_Corr'] = np.where(rolling_corr < -0.5, 1, 0)
                        
                        if 'log_expander' in globals() and log_expander is not None:
                            with log_expander:
                                st.success(f"---> [{symbol}] USDTRY verisi eklendi.")
                    else:
                        if 'log_expander' in globals() and log_expander is not None:
                            with log_expander:
                                st.warning(f"---> [{symbol}] USDTRY ile kesiÅŸen veri bulunamadÄ±.")
                else:
                    if 'log_expander' in globals() and log_expander is not None:
                        with log_expander:
                            st.warning(f"---> [{symbol}] USDTRY verisi alÄ±namadÄ±.")
            except Exception as e:
                if 'log_expander' in globals() and log_expander is not None:
                    with log_expander:
                        st.error(f"---> [{symbol}] USDTRY verisi eklenirken hata: {str(e)}")
                
                # Default deÄŸerler ekle
                df['USDTRY'] = 0
                df['USDTRY_Change'] = 0
                df['USDTRY_Change_5d'] = 0
                df['USDTRY_Change_20d'] = 0
                df['USD_Correlation'] = 0
                df['Is_USD_Positive_Corr'] = 0
                df['Is_USD_Negative_Corr'] = 0
            
            # 2. Euro/TL Kuru
            try:
                eurtry_data = get_stock_data_cached("EURTRY=X", period="5y", interval="1d")
                if eurtry_data is not None and not eurtry_data.empty:
                    # Tarih indekslerini eÅŸleÅŸtirme
                    common_idx = df.index.intersection(eurtry_data.index)
                    if len(common_idx) > 0:
                        eur_aligned = eurtry_data.loc[common_idx]['Close']
                        
                        # DÃ¶viz kuru deÄŸiÅŸim yÃ¼zdeleri
                        df['EURTRY'] = eur_aligned
                        df['EURTRY_Change'] = eur_aligned.pct_change()
                        
                        # Hisse/Euro korelasyonu (20 gÃ¼nlÃ¼k)
                        rolling_corr = df['Close'].rolling(window=20).corr(df['EURTRY'])
                        df['EUR_Correlation'] = rolling_corr
                        
                        if 'log_expander' in globals() and log_expander is not None:
                            with log_expander:
                                st.success(f"---> [{symbol}] EURTRY verisi eklendi.")
                    else:
                        if 'log_expander' in globals() and log_expander is not None:
                            with log_expander:
                                st.warning(f"---> [{symbol}] EURTRY ile kesiÅŸen veri bulunamadÄ±.")
                else:
                    if 'log_expander' in globals() and log_expander is not None:
                        with log_expander:
                            st.warning(f"---> [{symbol}] EURTRY verisi alÄ±namadÄ±.")
            except Exception as e:
                if 'log_expander' in globals() and log_expander is not None:
                    with log_expander:
                        st.error(f"---> [{symbol}] EURTRY verisi eklenirken hata: {str(e)}")
                
                # Default deÄŸerler ekle
                df['EURTRY'] = 0
                df['EURTRY_Change'] = 0
                df['EUR_Correlation'] = 0
            
            # 3. BIST SektÃ¶r Endeksleri
            sector_indices = {
                # Ana sektÃ¶r endeksleri
                'XBANK': 'Banka',
                'XUSIN': 'Sanayi',
                'XHOLD': 'Holding',
                'XGIDA': 'GÄ±da',
                'XTEKS': 'Tekstil',
                'XULAS': 'UlaÅŸtÄ±rma',
                'XTCRT': 'Ticaret',
                'XTRZM': 'Turizm',
                'XILTM': 'Ä°letiÅŸim',
                'XELKT': 'Elektrik',
                'XMANA': 'Madencilik',
                'XINSA': 'Ä°nÅŸaat'
            }
            
            # SektÃ¶r Ä°liÅŸkisi ve Korelasyon
            max_correlation = 0
            related_sector = None
            
            # Her hisse iÃ§in sektÃ¶r belirle
            stock_sector = None
            
            # SektÃ¶r tahmini
            if symbol.startswith("GAR") or symbol.startswith("AKB") or symbol.startswith("YKB") or symbol.startswith("HALK") or symbol.startswith("VAKB") or symbol.startswith("ISCTR"):
                stock_sector = "XBANK"
            elif symbol in ["THYAO", "PGSUS"]:
                stock_sector = "XULAS"
            elif symbol in ["MGROS", "BIMAS", "SOKM"]:
                stock_sector = "XTCRT"
            elif symbol in ["TAVHL", "MAVI"]:
                stock_sector = "XTRZM"
            elif symbol in ["TCELL", "TTKOM"]:
                stock_sector = "XILTM"
            elif symbol in ["TOASO", "FROTO", "KARSN", "OTKAR"]:
                stock_sector = "XUSIN"  # Otomotiv
            elif symbol in ["KCHOL", "SAHOL", "DOHOL"]:
                stock_sector = "XHOLD"
            
            # Her sektÃ¶r endeksi iÃ§in veri al ve korelasyon hesapla
            for index_code, sector_name in sector_indices.items():
                try:
                    index_data = get_stock_data_cached(f"{index_code}.IS", period="5y", interval="1d")
                    if index_data is not None and not index_data.empty:
                        # Tarih indekslerini eÅŸleÅŸtirme
                        common_idx = df.index.intersection(index_data.index)
                        if len(common_idx) > 10:  # En az 10 gÃ¼nlÃ¼k ortak veri olmalÄ±
                            stock_prices = df.loc[common_idx]['Close']
                            index_prices = index_data.loc[common_idx]['Close']
                            
                            # 20 gÃ¼nlÃ¼k korelasyon
                            corr_20d = stock_prices.rolling(window=20).corr(index_prices)
                            
                            # 60 gÃ¼nlÃ¼k korelasyon
                            corr_60d = stock_prices.rolling(window=60).corr(index_prices)
                            
                            # Son korelasyon (tÃ¼m veri)
                            overall_corr = stock_prices.corr(index_prices)
                            
                            # En yÃ¼ksek korelasyona sahip sektÃ¶rÃ¼ belirle
                            if abs(overall_corr) > abs(max_correlation):
                                max_correlation = overall_corr
                                related_sector = index_code
                            
                            # Korelasyon sÃ¼tunlarÄ± ekle
                            df[f'{index_code}_Corr_20d'] = corr_20d
                            df[f'{index_code}_Corr_60d'] = corr_60d
                            
                            # Son deÄŸiÅŸimleri ekle
                            df[f'{index_code}_Change_1d'] = index_prices.pct_change()
                            df[f'{index_code}_Change_5d'] = index_prices.pct_change(5)
                            
                            # Hissenin kendi sektÃ¶rÃ¼ ise daha fazla analiz
                            if index_code == stock_sector:
                                # Hissenin sektÃ¶r performansÄ±na gÃ¶re durumu (1=daha iyi, -1=daha kÃ¶tÃ¼)
                                stock_perf = df.loc[common_idx]['Close'].pct_change(5).iloc[-1] if len(common_idx) > 5 else 0
                                sector_perf = index_prices.pct_change(5).iloc[-1] if len(common_idx) > 5 else 0
                                
                                df['Sector_Outperformance'] = 1 if stock_perf > sector_perf else (-1 if stock_perf < sector_perf else 0)
                                df['Sector_Outperformance_Ratio'] = stock_perf / sector_perf if sector_perf != 0 else 0
                            
                            if 'log_expander' in globals() and log_expander is not None:
                                with log_expander:
                                    st.success(f"---> [{symbol}] {index_code} sektÃ¶r verisi eklendi. Korelasyon: {overall_corr:.3f}")
                        else:
                            if 'log_expander' in globals() and log_expander is not None:
                                with log_expander:
                                    st.warning(f"---> [{symbol}] {index_code} ile yeterli kesiÅŸen veri bulunamadÄ±.")
                    else:
                        if 'log_expander' in globals() and log_expander is not None:
                            with log_expander:
                                st.warning(f"---> [{symbol}] {index_code} verisi alÄ±namadÄ±.")
                
                except Exception as e:
                    if 'log_expander' in globals() and log_expander is not None:
                        with log_expander:
                            st.error(f"---> [{symbol}] {index_code} sektÃ¶r verisi eklenirken hata: {str(e)}")
            
            # En yÃ¼ksek korelasyonlu sektÃ¶rÃ¼ kaydet
            if related_sector:
                df['Most_Correlated_Sector'] = related_sector
                df['Sector_Correlation'] = max_correlation
                
                if 'log_expander' in globals() and log_expander is not None:
                    with log_expander:
                        st.info(f"---> [{symbol}] En yÃ¼ksek korelasyonlu sektÃ¶r: {related_sector} ({max_correlation:.3f})")
            else:
                df['Most_Correlated_Sector'] = "Unknown"
                df['Sector_Correlation'] = 0
            
            # SektÃ¶r belirlenebilmiÅŸse ekstra Ã¶zellikler ekle
            if stock_sector:
                df['Stock_Sector'] = stock_sector
                
                # SektÃ¶r ile hisse eÅŸleÅŸiyorsa 1, deÄŸilse 0
                df['Is_Sector_Match'] = 1 if stock_sector == related_sector else 0
                
                if 'log_expander' in globals() and log_expander is not None:
                    with log_expander:
                        st.info(f"---> [{symbol}] Hisse sektÃ¶rÃ¼: {stock_sector}")
            else:
                df['Stock_Sector'] = "Unknown"
                df['Is_Sector_Match'] = 0
            
            # 4. BIST 30, 50, 100 ve Genel Endeksler Korelasyonu
            try:
                for main_index in ['XU030.IS', 'XU050.IS', 'XU100.IS', 'XUTUM.IS']:
                    index_name = main_index.replace('.IS', '')
                    index_data = get_stock_data_cached(main_index, period="5y", interval="1d")
                    
                    if index_data is not None and not index_data.empty:
                        # Tarih indekslerini eÅŸleÅŸtirme
                        common_idx = df.index.intersection(index_data.index)
                        if len(common_idx) > 10:
                            stock_prices = df.loc[common_idx]['Close']
                            index_prices = index_data.loc[common_idx]['Close']
                            
                            # Korelasyon hesapla
                            corr_20d = stock_prices.rolling(window=20).corr(index_prices)
                            corr_60d = stock_prices.rolling(window=60).corr(index_prices)
                            
                            # Beta hesapla (60 gÃ¼nlÃ¼k pencerede)
                            index_return = index_prices.pct_change().dropna()
                            stock_return = stock_prices.pct_change().dropna()
                            
                            # KesiÅŸen indeksler
                            beta_idx = index_return.index.intersection(stock_return.index)
                            if len(beta_idx) > 30:
                                aligned_index_return = index_return.loc[beta_idx]
                                aligned_stock_return = stock_return.loc[beta_idx]
                                
                                # 60 gÃ¼nlÃ¼k pencerede beta hesapla
                                rolling_cov = aligned_stock_return.rolling(window=60).cov(aligned_index_return)
                                rolling_var = aligned_index_return.rolling(window=60).var()
                                beta = rolling_cov / rolling_var
                                
                                # Dataframe'e ekle
                                beta_series = pd.Series(0, index=df.index)  # TÃ¼m indeksleri kapsayan seri
                                beta_series.loc[beta.index] = beta  # HesaplanmÄ±ÅŸ deÄŸerleri yerleÅŸtir
                                df[f'{index_name}_Beta'] = beta_series
                            
                            # Dataframe'e ekle
                            df[f'{index_name}_Corr_20d'] = corr_20d
                            df[f'{index_name}_Corr_60d'] = corr_60d
                            
                            # Son deÄŸiÅŸimleri ekle
                            df[f'{index_name}_Change_1d'] = index_prices.pct_change()
                            df[f'{index_name}_Change_5d'] = index_prices.pct_change(5)
                            
                            if 'log_expander' in globals() and log_expander is not None:
                                with log_expander:
                                    st.success(f"---> [{symbol}] {index_name} endeks verisi eklendi.")
                        else:
                            if 'log_expander' in globals() and log_expander is not None:
                                with log_expander:
                                    st.warning(f"---> [{symbol}] {index_name} ile yeterli kesiÅŸen veri bulunamadÄ±.")
                    else:
                        if 'log_expander' in globals() and log_expander is not None:
                            with log_expander:
                                st.warning(f"---> [{symbol}] {index_name} verisi alÄ±namadÄ±.")
            except Exception as e:
                if 'log_expander' in globals() and log_expander is not None:
                    with log_expander:
                        st.error(f"---> [{symbol}] Ana endeks verileri eklenirken hata: {str(e)}")
            
            # 5. CDS (Ãœlke Risk Primi) - varsayÄ±lan deÄŸerler ekle, gerÃ§ek veri iÃ§in dÄ±ÅŸ kaynak gerekebilir
            # Not: Bu veriyi almak iÃ§in doÄŸrudan API olmadÄ±ÄŸÄ±ndan basitleÅŸtirilmiÅŸ bir yaklaÅŸÄ±m kullanabiliriz
            # GerÃ§ek uygulamada bu veri dÄ±ÅŸ API'lerden veya CSV dosyalarÄ±ndan alÄ±nabilir
            # Åimdilik tÃ¼m gÃ¼nler iÃ§in sabit bir deÄŸer atayalÄ±m
            df['TR_CDS'] = 300  # Ã–rnek deÄŸer, gerÃ§ek uygulamada gÃ¼ncel deÄŸer kullanÄ±lmalÄ±
            
            # 6. Faiz OranlarÄ± - varsayÄ±lan deÄŸerler ekle, gerÃ§ek veri iÃ§in dÄ±ÅŸ kaynak gerekebilir
            # Not: TCMB ve tahvil faizlerini almak iÃ§in Ã¶zel API'ler kullanÄ±labilir
            # Åimdilik tÃ¼m gÃ¼nler iÃ§in sabit deÄŸerler atayalÄ±m
            df['TCMB_Policy_Rate'] = 25  # Ã–rnek deÄŸer, gerÃ§ek uygulamada gÃ¼ncel deÄŸer kullanÄ±lmalÄ±
            df['TR_2Y_Bond_Yield'] = 30  # Ã–rnek deÄŸer, gerÃ§ek uygulamada gÃ¼ncel deÄŸer kullanÄ±lmalÄ±
            df['TR_10Y_Bond_Yield'] = 27  # Ã–rnek deÄŸer, gerÃ§ek uygulamada gÃ¼ncel deÄŸer kullanÄ±lmalÄ±
            
            # 7. Enflasyon - varsayÄ±lan deÄŸerler ekle, gerÃ§ek veri iÃ§in dÄ±ÅŸ kaynak gerekebilir
            # Not: Enflasyon deÄŸerleri genellikle aylÄ±k aÃ§Ä±klanÄ±r, gÃ¼nlÃ¼k veri olarak kullanmak iÃ§in interpolasyon yapÄ±labilir
            # Åimdilik tÃ¼m gÃ¼nler iÃ§in sabit bir deÄŸer atayalÄ±m
            df['TUFE_YoY'] = 60  # Ã–rnek deÄŸer, gerÃ§ek uygulamada gÃ¼ncel deÄŸer kullanÄ±lmalÄ±
            df['UID_YoY'] = 70  # Ã–rnek deÄŸer, gerÃ§ek uygulamada gÃ¼ncel deÄŸer kullanÄ±lmalÄ±
            
            # Tarihe baÄŸlÄ± deÄŸiÅŸim iÃ§in: GerÃ§ek uygulamada tarih bazlÄ± veri ekle
            # df['TUFE_YoY'] = df.index.map(lambda x: {
            #    pd.Timestamp('2023-01-01'): 60,
            #    pd.Timestamp('2023-02-01'): 62,
            #    # ... diÄŸer tarihler
            # }.get(pd.Timestamp(x.year, x.month, 1), 60))
            
            # 8. Rakip Åirketler veya Korelasyon Analizi
            # SektÃ¶re baÄŸlÄ± olarak rakip ÅŸirketleri belirle
            competitors = []
            
            if stock_sector == "XBANK":
                competitors = ["GARAN.IS", "AKBNK.IS", "YKBNK.IS", "HALKB.IS", "VAKBN.IS", "ISCTR.IS"]
            elif stock_sector == "XULAS":
                competitors = ["THYAO.IS", "PGSUS.IS"]
            elif stock_sector == "XTCRT":
                competitors = ["MGROS.IS", "BIMAS.IS", "SOKM.IS"]
            
            # Hisse kendisi hariÃ§ rakipleri filtrele
            competitors = [comp for comp in competitors if comp != f"{symbol}"]
            
            if competitors:
                # Rakiplerin ortalama performansÄ±nÄ± hesapla
                comp_returns = pd.DataFrame(index=df.index)
                
                for comp in competitors[:3]:  # En fazla 3 rakip
                    try:
                        comp_data = get_stock_data_cached(comp, period="2y", interval="1d")
                        if comp_data is not None and not comp_data.empty:
                            # Tarih indekslerini eÅŸleÅŸtirme
                            common_idx = df.index.intersection(comp_data.index)
                            if len(common_idx) > 10:
                                comp_close = comp_data.loc[common_idx]['Close']
                                comp_return = comp_close.pct_change()
                                comp_returns[comp] = comp_return
                                
                                # Rakip korelasyonu
                                corr = df.loc[common_idx]['Close'].pct_change().corr(comp_return)
                                df[f'{comp.replace(".IS", "")}_Corr'] = corr
                                
                                # Son dÃ¶nem performans farkÄ± (5 gÃ¼n)
                                if len(common_idx) > 5:
                                    stock_5d_return = df.loc[common_idx]['Close'].pct_change(5).iloc[-1]
                                    comp_5d_return = comp_close.pct_change(5).iloc[-1]
                                    df[f'{comp.replace(".IS", "")}_Perf_Diff'] = stock_5d_return - comp_5d_return
                                
                                if 'log_expander' in globals() and log_expander is not None:
                                    with log_expander:
                                        st.success(f"---> [{symbol}] {comp} rakip verisi eklendi. Korelasyon: {corr:.3f}")
                            else:
                                if 'log_expander' in globals() and log_expander is not None:
                                    with log_expander:
                                        st.warning(f"---> [{symbol}] {comp} ile yeterli kesiÅŸen veri bulunamadÄ±.")
                        else:
                            if 'log_expander' in globals() and log_expander is not None:
                                with log_expander:
                                    st.warning(f"---> [{symbol}] {comp} verisi alÄ±namadÄ±.")
                    
                    except Exception as e:
                        if 'log_expander' in globals() and log_expander is not None:
                            with log_expander:
                                st.error(f"---> [{symbol}] {comp} rakip verisi eklenirken hata: {str(e)}")
                
                # Rakiplerin ortalama performansÄ±
                if not comp_returns.empty:
                    avg_comp_return = comp_returns.mean(axis=1)
                    df['Competitors_Avg_Return'] = avg_comp_return
                    
                    # Rakiplere gÃ¶re performans (1=daha iyi, -1=daha kÃ¶tÃ¼)
                    avg_5d_comp_return = avg_comp_return.rolling(window=5).mean().iloc[-1] if len(avg_comp_return) > 5 else 0
                    stock_5d_return = df['Close'].pct_change(5).iloc[-1] if len(df) > 5 else 0
                    
                    df['Competitors_Outperformance'] = 1 if stock_5d_return > avg_5d_comp_return else (-1 if stock_5d_return < avg_5d_comp_return else 0)
                    df['Competitors_Outperformance_Ratio'] = stock_5d_return / avg_5d_comp_return if avg_5d_comp_return != 0 else 0
            
            # TÃ¼m NaN deÄŸerleri temizle
            numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
            for col in numeric_cols:
                if df[col].isnull().any():
                    df[col] = df[col].fillna(0)
            
            if 'log_expander' in globals() and log_expander is not None:
                with log_expander:
                    st.success(f"--> [{symbol}] Makroekonomik ve SektÃ¶rel veri ekleme tamamlandÄ±.")
            
            return df
        
        except Exception as e:
            if 'log_expander' in globals() and log_expander is not None:
                with log_expander:
                    st.error(f"--> [{symbol}] Makroekonomik ve SektÃ¶rel veri eklenirken genel hata: {str(e)}")
                st.error(traceback.format_exc())
            
            # Hata durumunda orijinal veriyi dÃ¶ndÃ¼r
            return df

    # --- Tarama MantÄ±ÄŸÄ± ---
    if st.button("Tarama BaÅŸlat", type="primary", use_container_width=True, key="ml_start_scan"):
        # Sadece burada expander oluÅŸtur
        log_expander = st.expander("Ä°ÅŸlem GÃ¼nlÃ¼ÄŸÃ¼ (Detaylar iÃ§in tÄ±klayÄ±n)", expanded=False)
        
        with log_expander:
            st.info("[LOG] Tarama BaÅŸlat butonuna basÄ±ldÄ±.")
            st.info("[LOG] Tarama sÃ¼reci baÅŸlÄ±yor...")
            st.info(f"[PARAMETRELER] Tarama Modu: {scan_option}, Zaman Dilimi: {time_frame}, EÅŸik: {ml_threshold*100:.1f}%, Min. OlasÄ±lÄ±k: {confidence_threshold}% ")
            st.info(f"[PARAMETRELER] GeliÅŸmiÅŸ GÃ¶stergeler: {use_advanced_features}, Piyasa Endeksi: {include_market_sentiment}, Haber Analizi: {use_sentiment_analysis}")
            st.info(f"[PARAMETRELER] Makroekonomik/SektÃ¶rel Veri: {use_macro_sector_data}")
            st.info("[MODEL GÃœNCELLENDÄ°] Elliott DalgalarÄ±, Fibonacci Retracement ve Makroekonomik gÃ¶stergeler eklendi!")
            st.info("Tarama iÅŸlemi baÅŸlatÄ±ldÄ±. SonuÃ§lar hazÄ±rlanÄ±yor...")
        
        if not libs_installed:
             st.error("Gerekli kÃ¼tÃ¼phaneler yÃ¼klenemediÄŸi iÃ§in tarama baÅŸlatÄ±lamÄ±yor.")
             st.stop()

        # Ana sonuÃ§ container'Ä±
        result_container = st.container()

        try:
            # Hisse listesini belirle
            stock_list = []
            if scan_option == "Ã–zel Liste":
                if custom_stocks:
                    stock_list = [s.strip().upper() for s in custom_stocks.split(",") if s.strip()]
                    stock_list = [s if s.endswith('.IS') else f"{s}.IS" for s in stock_list]
                if not stock_list:
                    with log_expander:
                        st.error("[HATA] Ã–zel Liste seÃ§ildi ancak hisse kodu girilmedi.")
                    st.stop()
            else:
                # Sabit listeler (Gerekirse gÃ¼ncellenmeli)
                bist30 = ["AKBNK.IS", "ARCLK.IS", "ASELS.IS", "BIMAS.IS", "EKGYO.IS", "EREGL.IS", "FROTO.IS", "GARAN.IS", "HALKB.IS", "ISCTR.IS", "KCHOL.IS", "KOZAA.IS", "KOZAL.IS", "KRDMD.IS", "PETKM.IS", "PGSUS.IS", "SAHOL.IS", "SASA.IS", "SISE.IS", "TAVHL.IS", "TCELL.IS", "THYAO.IS", "TOASO.IS", "TUPRS.IS", "VAKBN.IS", "YKBNK.IS", "VESTL.IS", "AKSEN.IS", "ENJSA.IS", "SOKM.IS"]
                bist50_extra = ["ALARK.IS", "ALBRK.IS", "DOHOL.IS", "ENKAI.IS", "GESAN.IS", "GUBRF.IS", "HEKTS.IS", "IPEKE.IS", "MAVI.IS", "MGROS.IS", "ODAS.IS", "OYAKC.IS", "SKBNK.IS", "TSKB.IS", "TTKOM.IS", "ULKER.IS", "YATAS.IS", "ZOREN.IS", "DOAS.IS", "TRGYO.IS"]
                bist100_extra = ["AEFES.IS", "AKSA.IS", "ALCTL.IS", "ALGYO.IS", "ANACM.IS", "ASUZU.IS", "AYDEM.IS", "BAGFS.IS", "BANVT.IS", "BRISA.IS", "BRSAN.IS", "CCOLA.IS", "CIMSA.IS", "DEVA.IS", "EGEEN.IS", "ERBOS.IS", "GLYHO.IS", "GSDHO.IS", "INDES.IS", "ISDMR.IS", "ISGYO.IS", "KAREL.IS", "KARSN.IS", "KARTN.IS", "KONTR.IS", "LOGO.IS", "MPARK.IS", "NETAS.IS", "NTHOL.IS", "OTKAR.IS", "PARSN.IS", "SELEC.IS", "SMRTG.IS", "TATGD.IS", "TKFEN.IS", "TMSN.IS", "TRCAS.IS", "VESBE.IS", "YKGYO.IS", "QUAGR.IS", "KLMSN.IS", "KZBGY.IS", "MAGEN.IS", "MNDRS.IS", "PENTA.IS", "AKFGY.IS", "AYGAZ.IS", "IHLGM.IS", "ISMEN.IS", "AKSA.IS"]

                if scan_option == "BIST 30": stock_list = bist30
                elif scan_option == "BIST 50": stock_list = bist30 + bist50_extra
                elif scan_option == "BIST 100": stock_list = bist30 + bist50_extra + bist100_extra
                elif scan_option == "TÃ¼m BIST":
                    # TÃ¼m BIST hisselerini al
                    try:
                        from data.stock_data import get_all_bist_stocks
                        all_bist_stocks = get_all_bist_stocks()
                        stock_list = [stock + ".IS" if not stock.endswith(".IS") else stock for stock in all_bist_stocks]
                        with log_expander:
                            st.info(f"[LOG] TÃ¼m BIST seÃ§eneÄŸi: {len(stock_list)} hisse bulundu.")
                    except Exception as e:
                        with log_expander:
                            st.error(f"[HATA] TÃ¼m BIST hisseleri alÄ±namadÄ±: {str(e)}")
                            st.info("[LOG] Fallback: BIST 100 listesi kullanÄ±lÄ±yor.")
                        stock_list = bist30 + bist50_extra + bist100_extra

            if not stock_list:
                with log_expander:
                    st.error("[HATA] Hisse listesi oluÅŸturulamadÄ±.")
                st.stop()
            
            with log_expander:
                st.info(f"[LOG] Ä°ÅŸlenecek toplam hisse sayÄ±sÄ±: {len(stock_list)}")
                st.code(", ".join(stock_list[:10]) + "..." if len(stock_list) > 10 else ", ".join(stock_list))

            # Ana ekranda toplam taranacak hisse sayÄ±sÄ±nÄ± gÃ¶ster
            result_container.info(f"Toplam {len(stock_list)} hisse taranÄ±yor...")
            # Hisse listesini gÃ¶sterme kodunu kaldÄ±rdÄ±k
            
            # Zaman dilimine gÃ¶re periyot ve interval belirle
            # Daha fazla geÃ§miÅŸ veri genellikle daha iyi modelleme saÄŸlar
            if time_frame == "4 Saat":
                period = "60d" # 2 ay
                interval = "1h" # Saatlik veri
                prediction_periods = 1 # 1 gÃ¼nlÃ¼k periyot
                days_to_predict = 1
            elif time_frame == "1 GÃ¼n":
                period = "5y" # 5 yÄ±l - Daha uzun tarihsel veri
                interval = "1d"
                prediction_periods = 1 # 1 gÃ¼nlÃ¼k periyot
                days_to_predict = 1
            elif time_frame == "1 Hafta":
                period = "5y" # 5 yÄ±l - Daha uzun tarihsel veri
                interval = "1d" # HaftalÄ±k iÃ§in gÃ¼nlÃ¼k veri kullanÄ±p 5 gÃ¼n sonrasÄ±na bakÄ±lÄ±r
                prediction_periods = 7 # 7 gÃ¼n (1 hafta)
                days_to_predict = 7
            else:  # 1 Ay
                period = "5y" # 5 yÄ±l - Daha uzun tarihsel veri
                interval = "1d" # AylÄ±k iÃ§in gÃ¼nlÃ¼k veri kullanÄ±p 30 gÃ¼n sonrasÄ±na bakÄ±lÄ±r
                prediction_periods = 30 # 30 gÃ¼n (1 ay)
                days_to_predict = 30
                
            with log_expander:
                st.info(f"[LOG] Zaman Dilimi: {time_frame}, Tahmin Edilecek GÃ¼n: {days_to_predict}")
                if days_to_predict != prediction_periods:
                    st.info(f"[LOG] KullanÄ±cÄ± tahmin gÃ¼n sayÄ±sÄ±nÄ± ({days_to_predict}) zaman diliminden ({prediction_periods}) farklÄ± ayarladÄ±. Tahmin {days_to_predict} gÃ¼n iÃ§in yapÄ±lacak.")

            # Test amaÃ§lÄ± Ã¶rnek veri kontrolÃ¼
            with log_expander:
                st.info("THYAO hisse verisi test ediliyor... Ä°nternet baÄŸlantÄ±nÄ±zÄ± kontrol edin.")
                test_data = get_stock_data_cached("THYAO.IS", period="7d", interval="1d", cache_key_suffix="_test")
                if test_data is not None and not test_data.empty:
                    st.success(f"Veri kaynaÄŸÄ± baÄŸlantÄ±sÄ± baÅŸarÄ±lÄ±: THYAO test verisi alÄ±ndÄ± ({len(test_data)} satÄ±r)")
                    st.dataframe(test_data.head(3))
                else:
                    st.error("THYAO test verisi alÄ±namadÄ±! Ä°nternet baÄŸlantÄ±nÄ±zÄ± ve yfinance API durumunu kontrol edin.")

            # BIST-100 endeksini al (piyasa duyarlÄ±lÄ±ÄŸÄ± iÃ§in)
            bist100_data = None
            if include_market_sentiment:
                with log_expander:
                    st.info("BIST 100 endeks verisi alÄ±nÄ±yor...")
                bist100_data = get_stock_data_cached("XU100.IS", period=period, interval=interval, cache_key_suffix="_bist100")
                if bist100_data is not None and not bist100_data.empty:
                    bist100_data = calculate_technical_indicators(bist100_data) # Temel gÃ¶stergeler yeterli olabilir
                    if use_advanced_features:
                         bist100_data = calculate_advanced_indicators(bist100_data) # Ä°stenirse geliÅŸmiÅŸler de eklenebilir
                    with log_expander:
                        st.info("BIST 100 verisi iÅŸlendi.")
                else:
                    with log_expander:
                        st.warning("BIST 100 verisi alÄ±namadÄ±, piyasa duyarlÄ±lÄ±ÄŸÄ± Ã¶zelliÄŸi kullanÄ±lamayacak.")
                    include_market_sentiment = False # KullanÄ±lamÄ±yorsa kapat

            # SonuÃ§larÄ± saklamak iÃ§in liste
            prediction_results = []
            # Ä°lerleme Ã§ubuÄŸu
            progress_bar = st.progress(0)
            
            # Ä°lerleme bilgisi iÃ§in boÅŸ alan
            progress_info = st.empty()
            
            # status_text = st.empty() # ArtÄ±k gerekli deÄŸil, tÃ¼m mesajlar log_expander iÃ§inde
            total_stocks = len(stock_list)

            # Geriye dÃ¶nÃ¼k test sonuÃ§larÄ± iÃ§in DataFrame
            if backtesting:
                backtesting_results_list = []

            # Her hisse iÃ§in tahmin yap
            with log_expander:
                st.info("[LOG] Hisse senedi iÅŸleme dÃ¶ngÃ¼sÃ¼ baÅŸlÄ±yor...")
                
            for i, stock_symbol in enumerate(stock_list):
                # DÃ¶ngÃ¼ye girildiÄŸini logla
                with log_expander:
                    st.info(f"=== [{i+1}/{total_stocks}] DÃ¶ngÃ¼ BaÅŸladÄ±: {stock_symbol} ===")
                    st.text(f"[{i+1}/{total_stocks}] Ä°ÅŸleniyor: {stock_symbol}")
                
                current_progress = (i + 1) / total_stocks
                # status_text.text(f"[{i+1}/{total_stocks}] Ä°ÅŸleniyor: {stock_symbol}") # ArtÄ±k gerekli deÄŸil
                progress_bar.progress(current_progress)
                
                # Ä°lerleme bilgisini ana ekranda gÃ¶ster
                progress_info.info(f"Ä°ÅŸleniyor: {i+1}/{total_stocks} - Mevcut: {stock_symbol}")
                
                try:
                    # 1. Hisse verilerini al
                    with log_expander:
                        st.info(f"-> {stock_symbol}: get_stock_data_cached Ã§aÄŸrÄ±lÄ±yor (Period: {period}, Interval: {interval})...")
                    # Cache anahtarÄ±na threshold ekle (farklÄ± threshold'lar iÃ§in farklÄ± cache)
                    cache_suffix = f"_threshold_{ml_threshold:.3f}_conf_{confidence_threshold}"
                    stock_data = get_stock_data_cached(stock_symbol, period=period, interval=interval, cache_key_suffix=cache_suffix)
                    
                    # Veri kontrolÃ¼
                    if stock_data is None or stock_data.empty:
                         with log_expander:
                             st.error(f"-> {stock_symbol} iÃ§in get_stock_data_cached'den geÃ§erli veri ALINAMADI. AtlanÄ±yor.")
                         continue # Sonraki hisseye geÃ§
                    elif len(stock_data) < 60:
                        with log_expander:
                            st.warning(f"-> {stock_symbol} iÃ§in yeterli (<60 bar) veri yok ({len(stock_data)} satÄ±r). AtlanÄ±yor.")
                        continue # Sonraki hisseye geÃ§
                    else:
                        with log_expander:
                            st.success(f"-> {stock_symbol}: Veri baÅŸarÄ±yla alÄ±ndÄ± ve kontrol edildi ({len(stock_data)} satÄ±r).")

                    # 2. Teknik gÃ¶stergeleri hesapla
                    with log_expander:
                        st.info(f"-> {stock_symbol}: Teknik gÃ¶stergeler hesaplanÄ±yor...")
                    stock_data = calculate_technical_indicators(stock_data)
                    if use_advanced_features:
                        stock_data = calculate_advanced_indicators(stock_data)
                    with log_expander:
                        st.success(f"-> {stock_symbol}: Teknik gÃ¶stergeler hesaplandÄ±.")

                    # 3. Piyasa duyarlÄ±lÄ±ÄŸÄ±nÄ± dahil et (opsiyonel)
                    if include_market_sentiment and bist100_data is not None:
                        # Tarih indekslerini eÅŸleÅŸtir (UTC'siz varsayÄ±lÄ±yor)
                        common_index = stock_data.index.intersection(bist100_data.index)
                        if len(common_index) > 30:
                            stock_data = stock_data.loc[common_index]
                            bist_data_aligned = bist100_data.loc[common_index]
                            for col in bist_data_aligned.columns:
                                if col not in ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits'] and f'BIST_{col}' not in stock_data.columns:
                                    stock_data[f'BIST_{col}'] = bist_data_aligned[col]
                        else:
                            with log_expander:
                                st.info(f"-> {stock_symbol}: BIST100 ile yeterli ortak tarih ({len(common_index)}<30) yok.")
                            # Piyasa Ã¶zelliÄŸi olmadan devam edilebilir veya hisse atlanabilir
                            # continue

                    # 4. DuyarlÄ±lÄ±k analizi verilerini ekle (opsiyonel)
                    sentiment_column_exists = False
                    if use_sentiment_analysis:
                        stock_data, sentiment_added = add_sentiment_data(stock_data, stock_symbol)
                        sentiment_column_exists = sentiment_added
                        if sentiment_added:
                            with log_expander:
                                # Veri kalitesini kontrol et
                                sentiment_nan_count = stock_data['Gemini_Sentiment'].isna().sum()
                                if sentiment_nan_count > 0:
                                    st.warning(f"-> {stock_symbol}: DuyarlÄ±lÄ±k verisi eklendi ancak {sentiment_nan_count} NaN deÄŸer iÃ§eriyor.")
                                else:
                                    st.success(f"-> {stock_symbol}: DuyarlÄ±lÄ±k verisi baÅŸarÄ±yla eklendi (NaN yok).")
                                # st.dataframe(stock_data[['Close', 'Gemini_Sentiment']].tail()) # Son deÄŸerleri kontrol etmek iÃ§in
                        else:
                            with log_expander:
                                 st.warning(f"-> {stock_symbol}: DuyarlÄ±lÄ±k verisi eklenemedi.")
                    else:
                        # Analiz kullanÄ±lmasa bile sÃ¼tunu 0 ile ekle (modelin tutarlÄ±lÄ±ÄŸÄ± iÃ§in)
                        if 'Gemini_Sentiment' not in stock_data.columns:
                            stock_data['Gemini_Sentiment'] = 0.0
                            sentiment_column_exists = True # Teknik olarak sÃ¼tun var artÄ±k
                            with log_expander:
                                st.info(f"-> {stock_symbol}: DuyarlÄ±lÄ±k analizi kapalÄ±, 'Gemini_Sentiment' sÃ¼tunu 0 olarak eklendi.")

                    # YENÄ°: 4.1 Makroekonomik ve SektÃ¶rel Verileri Ekle (opsiyonel)
                    if use_macro_sector_data:
                        with log_expander:
                            st.info(f"-> {stock_symbol}: Makroekonomik ve sektÃ¶rel veri ekleniyor...")
                        
                        # Makroekonomik ve sektÃ¶rel verileri ekle
                        stock_data = add_macro_sector_data(stock_data, stock_symbol)
                        
                        with log_expander:
                            # Eklenen veri kontrolÃ¼ 
                            macro_cols = [col for col in stock_data.columns if 
                                         col.startswith(('USD', 'EUR', 'XU', 'TR_', 'TUFE', 'Sector'))]
                            
                            if len(macro_cols) > 0:
                                st.success(f"-> {stock_symbol}: {len(macro_cols)} makroekonomik/sektÃ¶rel Ã¶zellik eklendi.")
                            else:
                                st.warning(f"-> {stock_symbol}: Makroekonomik/sektÃ¶rel Ã¶zellik eklenemedi.")
                    
                    # 5. Hedef deÄŸiÅŸkeni oluÅŸtur
                    with log_expander:
                        st.info(f"-> {stock_symbol}: Hedef deÄŸiÅŸken oluÅŸturuluyor (Periyot: {prediction_periods}, EÅŸik: {ml_threshold:.3f})...")
                    stock_data['Future_Close'] = stock_data['Close'].shift(-prediction_periods)
                    stock_data['Target_Pct'] = (stock_data['Future_Close'] / stock_data['Close']) - 1
                    stock_data['Target_Class'] = (stock_data['Target_Pct'] > ml_threshold).astype(int)
                    
                    # Nan deÄŸerli son satÄ±rlarÄ± kaldÄ±r (shift nedeniyle oluÅŸan)
                    rows_before_target_nan = len(stock_data)
                    stock_data = stock_data.dropna(subset=['Future_Close', 'Target_Pct', 'Target_Class'])
                    rows_after_target_nan = len(stock_data)
                    
                    with log_expander:
                        st.info(f"-> {stock_symbol}: Hedef deÄŸiÅŸken NaN temizliÄŸi: {rows_before_target_nan} -> {rows_after_target_nan} satÄ±r")
                        if rows_after_target_nan > 0:
                            target_counts = stock_data['Target_Class'].value_counts().to_dict()
                            st.info(f"-> {stock_symbol}: Veri Seti Hedef SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±: {target_counts}")
                        else:
                            st.warning(f"-> {stock_symbol}: Hedef deÄŸiÅŸken NaN temizliÄŸi sonrasÄ± veri kalmadÄ±! AtlanÄ±yor...")
                            continue

                    # 6. Ã–zellikleri ve hedefi tanÄ±mla, NaN/Inf iÅŸle
                    base_features = ['RSI', 'MACD', 'MACD_Signal','MACD_Histogram', 'BB_Upper', 'BB_Lower', 'BB_Width',
                                      'MA_5', 'MA_10', 'MA_20', 'MA_50', 'MA_200',
                                      'Volume_Change', 'Volume_MA_20','Volume_Ratio',
                                      'Momentum_5', 'Momentum_10', 'ROC_5', 'ROC_10',
                                      'Stoch_K', 'Stoch_D', 'ATR', 'OBV',
                                      'Daily_Return', 'Weekly_Return', 'Monthly_Return',
                                      'Volatility_5', 'Volatility_20',
                                      'Upper_Channel', 'Lower_Channel', 'Channel_Width',
                                      'MA_5_Slope', 'MA_20_Slope', 'MA_50_Slope']

                    # Advanced features list
                    advanced_features_list = []
                    if use_advanced_features:
                        adv_inds = ['Tenkan_sen', 'Kijun_sen', 'Senkou_span_A', 'Senkou_span_B', 'CMF',
                                    'Williams_%R', 'CCI', 'Aroon_Oscillator', 'Keltner_Upper', 'Keltner_Lower',
                                    'Donchian_Upper', 'Donchian_Lower', 'SAR', 'VI_plus', 'VI_minus', 'TRIX',
                                    'DPO', 'CMO', 'PVT', 'Price_Volume_Corr', 'Price_Volatility', 'Volume_Volatility',
                                    'Fib_38.2', 'Fib_50', 'Fib_61.8']
                        advanced_features_list.extend(adv_inds)

                    market_sentiment_features = [col for col in stock_data.columns if col.startswith('BIST_')] if include_market_sentiment else []
                    sentiment_analysis_features = ['Gemini_Sentiment'] if sentiment_column_exists else []

                    all_potential_features = base_features + advanced_features_list + market_sentiment_features + sentiment_analysis_features

                    features_to_use = [f for f in all_potential_features if f in stock_data.columns and pd.api.types.is_numeric_dtype(stock_data[f])]

                    columns_to_check = features_to_use + ['Target_Class']

                    with log_expander:
                         st.info(f"-> {stock_symbol}: Ã–zellik ve Hedef NaN/Inf kontrolÃ¼ yapÄ±lacak sÃ¼tun sayÄ±sÄ±: {len(columns_to_check)}")

                    initial_rows = len(stock_data)

                    inf_count = np.isinf(stock_data[features_to_use]).sum().sum()
                    if inf_count > 0:
                        with log_expander:
                            st.warning(f"-> {stock_symbol}: {inf_count} adet sonsuz deÄŸer bulundu ve NaN ile deÄŸiÅŸtiriliyor.")
                        stock_data.replace([np.inf, -np.inf], np.nan, inplace=True)

                    stock_data.dropna(subset=columns_to_check, inplace=True)
                    final_rows = len(stock_data)

                    if initial_rows > final_rows:
                         with log_expander:
                             st.info(f"-> {stock_symbol}: Ã–zellik/Hedef NaN temizliÄŸi: {initial_rows} -> {final_rows} satÄ±r ({initial_rows - final_rows} satÄ±r kaldÄ±rÄ±ldÄ±)." )

                    if len(stock_data) < 30:
                        with log_expander:
                            st.warning(f"-> {stock_symbol}: Ã–zellik/Hedef iÅŸlendikten sonra yeterli veri (<30) kalmadÄ±, atlanÄ±yor.")
                        continue
                    else:
                         with log_expander:
                             st.success(f"-> {stock_symbol}: Model eÄŸitimi iÃ§in yeterli veri var ({len(stock_data)} satÄ±r).")

                    # 7. Veriyi EÄŸitim ve Test Setlerine AyÄ±r - Deterministik
                    X = stock_data[features_to_use]
                    y = stock_data['Target_Class']
                    
                    # Veri setini indeks sÄ±rasÄ±na gÃ¶re dÃ¼zenle (deterministik)
                    X = X.sort_index()
                    y = y.sort_index()
                    
                    train_size = int(len(X) * 0.8)
                    X_train, X_test = X[:train_size], X[train_size:]
                    y_train, y_test = y[:train_size], y[train_size:]

                    with log_expander:
                        st.info(f"-> {stock_symbol}: Veri setleri oluÅŸturuldu - EÄŸitim: {len(X_train)} satÄ±r, Test: {len(X_test)} satÄ±r")

                    if len(X_train) < 20 or len(X_test) < 5:
                        with log_expander:
                            st.warning(f"-> {stock_symbol}: Yetersiz eÄŸitim ({len(X_train)}<20) veya test ({len(X_test)}<5) verisi, atlanÄ±yor.")
                        continue

                    class_counts = y_train.value_counts()
                    with log_expander:
                        st.info(f"-> {stock_symbol}: EÄŸitim Seti SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±: {dict(class_counts)}")

                    if len(class_counts) < 2:
                       with log_expander:
                           st.warning(f"-> {stock_symbol} EÄŸitim setinde sadece bir sÄ±nÄ±f ({class_counts.index[0]}) bulunuyor, model eÄŸitilemez, atlanÄ±yor.")
                       continue
                    minority_class_count = class_counts.min()
                    if minority_class_count < 5:
                        with log_expander:
                            st.warning(f"-> {stock_symbol}: EÄŸitim setindeki azÄ±nlÄ±k sÄ±nÄ±fÄ± Ã¶rneÄŸi Ã§ok az ({minority_class_count}<5). Model performansÄ± dÃ¼ÅŸÃ¼k olabilir.")

                    if len(class_counts) == 2 and (class_counts.max() / len(y_train)) > 0.99:
                        with log_expander:
                            st.warning(f"-> {stock_symbol}: EÄŸitim seti aÅŸÄ±rÄ± dengesiz! ({class_counts.max() / len(y_train) * 100:.1f}% Ã§oÄŸunluk sÄ±nÄ±fÄ±). Modelin azÄ±nlÄ±k sÄ±nÄ±fÄ±nÄ± Ã¶ÄŸrenmesi zor olabilir.")

                    # 8. Veriyi Ã–lÃ§eklendir - Deterministik seed ile
                    with log_expander:
                        st.info(f"-> {stock_symbol}: Veri Ã¶lÃ§eklendiriliyor (MinMaxScaler)..." )
                    
                    # Veri satÄ±rlarÄ±nÄ± sÄ±ralama deterministik hale getir
                    X_train = X_train.sort_index()
                    X_test = X_test.sort_index()
                    y_train = y_train.sort_index()
                    y_test = y_test.sort_index()
                    
                    scaler = MinMaxScaler()
                    X_train_scaled = scaler.fit_transform(X_train)
                    X_test_scaled = scaler.transform(X_test)
                    with log_expander:
                        st.success(f"-> {stock_symbol}: Veri Ã¶lÃ§eklendirme tamamlandÄ±.")

                    # 9. Model SeÃ§imi, EÄŸitimi ve Test Tahminleri (Ã–nceki loglar iyi)
                    trained_models = {}
                    test_predictions_proba = {}
                    count_0 = class_counts.get(0, 0)
                    count_1 = class_counts.get(1, 0)
                    scale_pos_weight_val = count_0 / count_1 if count_1 > 0 else 1
                    model_error = False
                    
                    # Model tipini tanÄ±mla - UI'dan alÄ±nan deÄŸer
                    model_name = model_selection
                    
                    with log_expander:
                        st.info(f"-> {stock_symbol}: SeÃ§ilen model: {model_name}")

                    # VeritabanÄ±nda model arama ve yÃ¼kleme
                    db_models_loaded = False
                    if use_db_models and not force_retrain:
                        with log_expander:
                            st.info(f"-> {stock_symbol}: VeritabanÄ±nda model aranÄ±yor...")
                        
                        try:
                            # SembolÃ¼ dÃ¼zenle
                            symbol_clean = stock_symbol.replace(".IS", "")
                            
                            # Modeli yÃ¼klemeyi dene
                            if model_name in ["RandomForest", "XGBoost", "LightGBM"]:
                                # Tek model iÃ§in yÃ¼kleme
                                db_model_info = load_ml_model(symbol_clean, model_name)
                                
                                if db_model_info:
                                    # MODEL YAÅ KONTROLÃœ EKLENDÄ°
                                    from datetime import datetime, timedelta
                                    
                                    # Son gÃ¼ncelleme tarihini kontrol et
                                    last_update_str = db_model_info.get('last_update_date', None)
                                    model_too_old = False
                                    
                                    if last_update_str:
                                        try:
                                            last_update = datetime.strptime(last_update_str, "%Y-%m-%d %H:%M:%S")
                                            days_old = (datetime.now() - last_update).days
                                            
                                            with log_expander:
                                                st.info(f"-> {stock_symbol}: {model_name} modeli {days_old} gÃ¼n Ã¶nce gÃ¼ncellendi.")
                                            
                                            # 7 gÃ¼nden eski modelleri yeniden eÄŸit
                                            if days_old > 7:
                                                model_too_old = True
                                                with log_expander:
                                                    st.warning(f"-> {stock_symbol}: {model_name} modeli Ã§ok eski ({days_old} gÃ¼n), yeniden eÄŸitilecek.")
                                        except ValueError:
                                            with log_expander:
                                                st.warning(f"-> {stock_symbol}: {model_name} modeli tarih formatÄ± bozuk, yeniden eÄŸitilecek.")
                                            model_too_old = True
                                    else:
                                        with log_expander:
                                            st.warning(f"-> {stock_symbol}: {model_name} modeli tarih bilgisi yok, yeniden eÄŸitilecek.")
                                        model_too_old = True
                                    
                                    # Model Ã§ok eski deÄŸilse kullan
                                    if not model_too_old:
                                        # Modeli geri yÃ¼kle
                                        model_data = db_model_info['model_data']
                                        loaded_model = pickle.loads(model_data)
                                        
                                        # Modeli kaydet
                                        trained_models[model_name] = loaded_model
                                        
                                        # Test seti tahminlerini yap
                                        test_predictions_proba[model_name] = loaded_model.predict_proba(X_test_scaled)[:, 1]
                                        
                                        with log_expander:
                                            st.success(f"-> {stock_symbol}: {model_name} modeli veritabanÄ±ndan baÅŸarÄ±yla yÃ¼klendi.")
                                            
                                            # Metrikleri gÃ¶ster
                                            if 'metrics' in db_model_info and db_model_info['metrics']:
                                                metrics = db_model_info['metrics']
                                                st.info(f"-> {stock_symbol}: {model_name} model metrikleri:")
                                                st.info(f"   DoÄŸruluk: {metrics.get('accuracy', 'N/A'):.3f}")
                                                st.info(f"   Kesinlik: {metrics.get('precision', 'N/A'):.3f}")
                                                st.info(f"   DuyarlÄ±lÄ±k: {metrics.get('recall', 'N/A'):.3f}")
                                                st.info(f"   F1 Skoru: {metrics.get('f1', 'N/A'):.3f}")
                                            
                                            # Son gÃ¼ncelleme tarihini gÃ¶ster
                                            if 'last_update_date' in db_model_info:
                                                st.info(f"-> {stock_symbol}: {model_name} son gÃ¼ncelleme: {db_model_info['last_update_date']}")
                                        
                                        db_models_loaded = True
                                    else:
                                        with log_expander:
                                            st.warning(f"-> {stock_symbol}: {model_name} modeli Ã§ok eski, yeniden eÄŸitilecek.")
                                else:
                                    with log_expander:
                                        st.warning(f"-> {stock_symbol}: {model_name} modeli veritabanÄ±nda bulunamadÄ±, eÄŸitilecek.")
                            
                            elif model_name in ["Ensemble", "Hibrit Model"]:
                                # TÃ¼m modelleri yÃ¼klemeyi dene
                                db_models = load_ml_model(symbol_clean)
                                
                                if db_models and len(db_models) > 0:
                                    with log_expander:
                                        st.info(f"-> {stock_symbol}: VeritabanÄ±nda {len(db_models)} model bulundu.")
                                    
                                    # Her modeli yÃ¼kle ve yaÅŸ kontrolÃ¼ yap
                                    for model_type, model_info in db_models.items():
                                        try:
                                            # MODEL YAÅ KONTROLÃœ EKLENDÄ°
                                            from datetime import datetime, timedelta
                                            
                                            # Son gÃ¼ncelleme tarihini kontrol et
                                            last_update_str = model_info.get('last_update_date', None)
                                            model_too_old = False
                                            
                                            if last_update_str:
                                                try:
                                                    last_update = datetime.strptime(last_update_str, "%Y-%m-%d %H:%M:%S")
                                                    days_old = (datetime.now() - last_update).days
                                                    
                                                    with log_expander:
                                                        st.info(f"-> {stock_symbol}: {model_type} modeli {days_old} gÃ¼n Ã¶nce gÃ¼ncellendi.")
                                                    
                                                    # 7 gÃ¼nden eski modelleri yeniden eÄŸit
                                                    if days_old > 7:
                                                        model_too_old = True
                                                        with log_expander:
                                                            st.warning(f"-> {stock_symbol}: {model_type} modeli Ã§ok eski ({days_old} gÃ¼n), atlanÄ±yor.")
                                                except ValueError:
                                                    with log_expander:
                                                        st.warning(f"-> {stock_symbol}: {model_type} modeli tarih formatÄ± bozuk, atlanÄ±yor.")
                                                    model_too_old = True
                                            else:
                                                with log_expander:
                                                    st.warning(f"-> {stock_symbol}: {model_type} modeli tarih bilgisi yok, atlanÄ±yor.")
                                                model_too_old = True
                                            
                                            # Model Ã§ok eski deÄŸilse kullan
                                            if not model_too_old:
                                                # Modeli geri yÃ¼kle
                                                model_data = model_info['model_data']
                                                loaded_model = pickle.loads(model_data)
                                                
                                                # Modeli kaydet
                                                trained_models[model_type] = loaded_model
                                                
                                                # Test seti tahminlerini yap
                                                test_predictions_proba[model_type] = loaded_model.predict_proba(X_test_scaled)[:, 1]
                                                
                                                with log_expander:
                                                    st.success(f"-> {stock_symbol}: {model_type} modeli veritabanÄ±ndan baÅŸarÄ±yla yÃ¼klendi.")
                                        except Exception as load_error:
                                            with log_expander:
                                                st.error(f"-> {stock_symbol}: {model_type} modeli yÃ¼klenirken hata: {str(load_error)}")
                                    
                                    # En az 1 model yÃ¼klendiyse baÅŸarÄ±lÄ± say
                                    if len(trained_models) > 0:
                                        db_models_loaded = True
                                        with log_expander:
                                            st.success(f"-> {stock_symbol}: {len(trained_models)} model baÅŸarÄ±yla yÃ¼klendi.")
                                    else:
                                        with log_expander:
                                            st.warning(f"-> {stock_symbol}: TÃ¼m modeller Ã§ok eski, yeniden eÄŸitim yapÄ±lacak.")
                                else:
                                    with log_expander:
                                        st.warning(f"-> {stock_symbol}: VeritabanÄ±nda model bulunamadÄ±, eÄŸitilecek.")
                        except Exception as db_error:
                            with log_expander:
                                st.error(f"-> {stock_symbol}: VeritabanÄ±ndan model yÃ¼klenirken hata: {str(db_error)}")
                    
                    # EÄŸer force_retrain aktifse veya model yÃ¼klenemezse/bulunamazsa eÄŸitim yap
                    if force_retrain or not db_models_loaded:
                        with log_expander:
                            if force_retrain:
                                st.info(f"-> {stock_symbol}: TÃ¼m modelleri yeniden eÄŸitme seÃ§eneÄŸi aktif, modeller eÄŸitilecek.")
                            elif not db_models_loaded:
                                st.info(f"-> {stock_symbol}: VeritabanÄ±nda model bulunamadÄ± veya yÃ¼klenemedi, eÄŸitim yapÄ±lacak.")

                    # stdout ve stderr'i geÃ§ici olarak yakalayÄ±p log_expander iÃ§ine yÃ¶nlendirme
                    stdout_capture = io.StringIO()
                    stderr_capture = io.StringIO()

                    # RandomForest model eÄŸitimi - eÄŸer veritabanÄ±nda yoksa veya zorla eÄŸitim seÃ§ildiyse
                    if (model_name in ["RandomForest", "Ensemble", "Hibrit Model"]) and (force_retrain or not db_models_loaded or "RandomForest" not in trained_models):
                        try:
                            with log_expander: st.info(f"-> {stock_symbol}: RandomForest modeli eÄŸitiliyor...")
                            
                            # stdout ve stderr'i yakala
                            with redirect_stdout(stdout_capture), redirect_stderr(stderr_capture):
                                rf_m = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced',
                                                         n_jobs=-1)
                                rf_m.fit(X_train_scaled, y_train)
                            
                            # Yakalanan Ã§Ä±ktÄ±larÄ± iÅŸlem gÃ¼nlÃ¼ÄŸÃ¼ne yÃ¶nlendir
                            captured_output = stdout_capture.getvalue() + stderr_capture.getvalue()
                            if captured_output.strip():
                                with log_expander: 
                                    if "Warning" in captured_output:
                                        st.warning("RandomForest UyarÄ±larÄ±:")
                                    st.text(captured_output)
                            
                            trained_models["RandomForest"] = rf_m
                            test_predictions_proba["RandomForest"] = rf_m.predict_proba(X_test_scaled)[:, 1]
                            
                            # Model veritabanÄ±na kaydet
                            try:
                                # Modeli pickle ile serialize et
                                model_data = pickle.dumps(rf_m)
                                
                                # Performans metrikleri hesapla
                                y_pred_test = rf_m.predict(X_test_scaled)
                                performance_metrics = {
                                    "accuracy": float(accuracy_score(y_test, y_pred_test)),
                                    "precision": float(precision_score(y_test, y_pred_test, zero_division=0)),
                                    "recall": float(recall_score(y_test, y_pred_test, zero_division=0)),
                                    "f1": float(f1_score(y_test, y_pred_test, zero_division=0))
                                }
                                
                                # Modeli veritabanÄ±na kaydet
                                model_saved = save_ml_model(
                                    symbol=stock_symbol.replace(".IS", ""),
                                    model_type="RandomForest",
                                    model_data=model_data,
                                    features_used=features_to_use,
                                    performance_metrics=performance_metrics
                                )
                                
                                with log_expander:
                                    if model_saved:
                                        st.success(f"-> {stock_symbol}: RandomForest modeli veritabanÄ±na kaydedildi.")
                                    else:
                                        st.warning(f"-> {stock_symbol}: RandomForest modeli veritabanÄ±na kaydedilemedi.")
                            except Exception as save_error:
                                with log_expander:
                                    st.error(f"-> {stock_symbol}: RandomForest modeli kaydedilirken hata: {str(save_error)}")
                                    
                            with log_expander: st.success(f"-> {stock_symbol}: RandomForest model eÄŸitimi baÅŸarÄ±lÄ±")
                        except Exception as m_e:
                            with log_expander: st.error(f"-> {stock_symbol}: RandomForest HatasÄ±: {m_e}")
                            model_error=True

                    # XGBoost model bloÄŸu - eÄŸer veritabanÄ±nda yoksa veya zorla eÄŸitim seÃ§ildiyse
                    if (model_name in ["XGBoost", "Ensemble", "Hibrit Model"]) and (force_retrain or not db_models_loaded or "XGBoost" not in trained_models):
                        try:
                            with log_expander: 
                                st.info(f"-> {stock_symbol}: XGBoost modeli eÄŸitiliyor...")
                            
                            with redirect_stdout(stdout_capture), redirect_stderr(stderr_capture):
                                xgb_model = xgb.XGBClassifier(
                                    n_estimators=100, 
                                    learning_rate=0.1, 
                                    random_state=42, 
                                    use_label_encoder=False, 
                                    eval_metric='logloss', 
                                    tree_method='hist', 
                                    scale_pos_weight=scale_pos_weight_val,
                                    verbosity=0
                                )
                                xgb_model.fit(X_train_scaled, y_train)
                            
                            captured_output = stdout_capture.getvalue() + stderr_capture.getvalue()
                            if captured_output.strip():
                                with log_expander:
                                    if "Warning" in captured_output:
                                        st.warning("XGBoost UyarÄ±larÄ±:")
                                    st.text(captured_output)
                            
                            trained_models["XGBoost"] = xgb_model
                            test_predictions_proba["XGBoost"] = xgb_model.predict_proba(X_test_scaled)[:, 1]
                            
                            # Model veritabanÄ±na kaydet
                            try:
                                # Modeli pickle ile serialize et
                                model_data = pickle.dumps(xgb_model)
                                
                                # Performans metrikleri hesapla
                                y_pred_test = xgb_model.predict(X_test_scaled)
                                performance_metrics = {
                                    "accuracy": float(accuracy_score(y_test, y_pred_test)),
                                    "precision": float(precision_score(y_test, y_pred_test, zero_division=0)),
                                    "recall": float(recall_score(y_test, y_pred_test, zero_division=0)),
                                    "f1": float(f1_score(y_test, y_pred_test, zero_division=0))
                                }
                                
                                # Modeli veritabanÄ±na kaydet
                                model_saved = save_ml_model(
                                    symbol=stock_symbol.replace(".IS", ""),
                                    model_type="XGBoost",
                                    model_data=model_data,
                                    features_used=features_to_use,
                                    performance_metrics=performance_metrics
                                )
                                
                                with log_expander:
                                    if model_saved:
                                        st.success(f"-> {stock_symbol}: XGBoost modeli veritabanÄ±na kaydedildi.")
                                    else:
                                        st.warning(f"-> {stock_symbol}: XGBoost modeli veritabanÄ±na kaydedilemedi.")
                            except Exception as save_error:
                                with log_expander:
                                    st.error(f"-> {stock_symbol}: XGBoost modeli kaydedilirken hata: {str(save_error)}")
                            
                            with log_expander: 
                                st.success(f"-> {stock_symbol}: XGBoost model eÄŸitimi baÅŸarÄ±lÄ±")
                        except Exception as m_e:
                            with log_expander: 
                                st.error(f"-> {stock_symbol}: XGBoost HatasÄ±: {m_e}")
                            model_error=True

                    # LightGBM model bloÄŸu - eÄŸer veritabanÄ±nda yoksa veya zorla eÄŸitim seÃ§ildiyse
                    if (model_name in ["LightGBM", "Ensemble", "Hibrit Model"]) and (force_retrain or not db_models_loaded or "LightGBM" not in trained_models):
                         try:
                            with log_expander: st.info(f"-> {stock_symbol}: LightGBM modeli eÄŸitiliyor...")
                            
                            # stdout ve stderr'i yakala
                            with redirect_stdout(stdout_capture), redirect_stderr(stderr_capture):
                                lgb_m = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=42, 
                                                          n_jobs=-1, class_weight='balanced', verbose=-1,
                                                          force_col_wise=True) # verbose=-1 ile loglarÄ± kapat
                                lgb_m.fit(X_train_scaled, y_train)
                            
                            # Yakalanan Ã§Ä±ktÄ±larÄ± iÅŸlem gÃ¼nlÃ¼ÄŸÃ¼ne yÃ¶nlendir 
                            captured_output = stdout_capture.getvalue() + stderr_capture.getvalue()
                            # LightGBM uyarÄ±larÄ±nÄ± sadece log_expander iÃ§inde gÃ¶ster, ana ekranda gÃ¶sterme
                            if captured_output.strip():
                                with log_expander: 
                                    if "Warning" in captured_output:
                                        st.warning("LightGBM UyarÄ±larÄ±:")
                                    st.text(captured_output)
                            
                            trained_models["LightGBM"] = lgb_m
                            test_predictions_proba["LightGBM"] = lgb_m.predict_proba(X_test_scaled)[:, 1]
                            
                            # Model veritabanÄ±na kaydet
                            try:
                                # Modeli pickle ile serialize et
                                model_data = pickle.dumps(lgb_m)
                                
                                # Performans metrikleri hesapla
                                y_pred_test = lgb_m.predict(X_test_scaled)
                                performance_metrics = {
                                    "accuracy": float(accuracy_score(y_test, y_pred_test)),
                                    "precision": float(precision_score(y_test, y_pred_test, zero_division=0)),
                                    "recall": float(recall_score(y_test, y_pred_test, zero_division=0)),
                                    "f1": float(f1_score(y_test, y_pred_test, zero_division=0))
                                }
                                
                                # Modeli veritabanÄ±na kaydet
                                model_saved = save_ml_model(
                                    symbol=stock_symbol.replace(".IS", ""),
                                    model_type="LightGBM",
                                    model_data=model_data,
                                    features_used=features_to_use,
                                    performance_metrics=performance_metrics
                                )
                                
                                with log_expander:
                                    if model_saved:
                                        st.success(f"-> {stock_symbol}: LightGBM modeli veritabanÄ±na kaydedildi.")
                                    else:
                                        st.warning(f"-> {stock_symbol}: LightGBM modeli veritabanÄ±na kaydedilemedi.")
                            except Exception as save_error:
                                with log_expander:
                                    st.error(f"-> {stock_symbol}: LightGBM modeli kaydedilirken hata: {str(save_error)}")
                            
                            with log_expander: st.success(f"-> {stock_symbol}: LightGBM model eÄŸitimi baÅŸarÄ±lÄ±")
                         except Exception as m_e:
                            with log_expander: st.error(f"-> {stock_symbol}: LightGBM HatasÄ±: {m_e}")
                            model_error=True

                    if not trained_models:
                        with log_expander:
                            st.error(f"-> {stock_symbol}: HiÃ§bir model eÄŸitilemedi, atlanÄ±yor.")
                        continue

                    if model_error and not trained_models.get(model_name):
                         if model_name not in ["Ensemble", "Hibrit Model"]:
                             with log_expander:
                                 st.error(f"-> {stock_symbol}: SeÃ§ilen model ({model_name}) eÄŸitilemedi, atlanÄ±yor.")
                             continue
                         else:
                             with log_expander:
                                 st.warning(f"-> {stock_symbol}: BazÄ± modeller eÄŸitilemedi, ancak en az bir model baÅŸarÄ±lÄ± olduÄŸu iÃ§in devam ediliyor.")

                    # 10. Geriye DÃ¶nÃ¼k Test Metrikleri (Ã–nceki loglar iyi)
                    if backtesting:
                        final_test_proba = None
                        current_model_name_bt = f"{stock_symbol}-{model_name}"

                        if model_name == "Ensemble" and len(test_predictions_proba) > 1:
                            final_test_proba = np.mean(list(test_predictions_proba.values()), axis=0)
                        elif model_name == "Hibrit Model" and len(test_predictions_proba) > 1:
                            weights_bt = [0.4, 0.35, 0.25][:len(test_predictions_proba)]
                            probas_bt = [test_predictions_proba.get(name) for name in trained_models.keys() if name in test_predictions_proba] # SÄ±ralÄ± al
                            if len(probas_bt) == len(weights_bt): # AÄŸÄ±rlÄ±k sayÄ±sÄ± eÅŸleÅŸiyorsa
                                 final_test_proba = np.average(probas_bt, axis=0, weights=weights_bt)
                            else: # EÅŸleÅŸmiyorsa basit ortalama
                                 final_test_proba = np.mean(probas_bt, axis=0)
                        elif model_name in test_predictions_proba: # Tek model
                            final_test_proba = test_predictions_proba[model_name]
                        elif test_predictions_proba: # SeÃ§ilen model yoksa ilkini al
                            first_model_name = list(test_predictions_proba.keys())[0]
                            final_test_proba = test_predictions_proba[first_model_name]
                            current_model_name_bt = f"{stock_symbol}-{first_model_name} (fallback)"


                        if final_test_proba is not None:
                            y_pred_binary_test = (final_test_proba > 0.5).astype(int)
                            bt_metrics = {
                                "Hisse-Model": current_model_name_bt,
                                "DoÄŸruluk": accuracy_score(y_test, y_pred_binary_test),
                                "Kesinlik": precision_score(y_test, y_pred_binary_test, zero_division=0),
                                "DuyarlÄ±lÄ±k": recall_score(y_test, y_pred_binary_test, zero_division=0),
                                "F1 Skoru": f1_score(y_test, y_pred_binary_test, zero_division=0)
                            }
                            with log_expander:
                                st.info(f"-> {stock_symbol}: Geriye DÃ¶nÃ¼k Test Sonucu:")
                            bt_df = pd.DataFrame([bt_metrics])
                            bt_df = bt_df.set_index("Hisse-Model")
                            bt_cols = ["DoÄŸruluk", "Kesinlik", "DuyarlÄ±lÄ±k", "F1 Skoru"]
                            for col in bt_cols:
                                bt_df[col] = bt_df[col].apply(lambda x: f"{x*100:.1f}%")
                            with log_expander:
                                st.info(bt_df.to_string())
                            backtesting_results_list.append(bt_metrics)
                        else:
                            with log_expander:
                                st.warning(f"-> {stock_symbol}: Geriye dÃ¶nÃ¼k test iÃ§in tahmin olasÄ±lÄ±ÄŸÄ± bulunamadÄ±.")

                    # 11. Son Veri Ä°Ã§in Tahmin Yap
                    with log_expander:
                        st.info(f"-> {stock_symbol}: Son veri noktasÄ± iÃ§in tahmin yapÄ±lÄ±yor...")
                    last_data_point = X.iloc[-1:].copy()
                    last_data_scaled = scaler.transform(last_data_point)

                    final_prediction_probas = {}
                    for name, model in trained_models.items():
                         try:
                             proba = model.predict_proba(last_data_scaled)[0, 1]
                             final_prediction_probas[name] = proba
                             with log_expander:
                                 st.info(f"---> [{stock_symbol}-{name}] Ham OlasÄ±lÄ±k: {proba:.4f}")
                         except Exception as final_pred_e:
                             with log_expander:
                                 st.error(f"Son Tahmin HatasÄ± ({stock_symbol}-{name}): {final_pred_e}")

                    if not final_prediction_probas:
                         with log_expander:
                             st.error(f"-> {stock_symbol}: Son veri iÃ§in tahmin olasÄ±lÄ±ÄŸÄ± Ã¼retilemedi, atlanÄ±yor.")
                         continue

                    # Nihai olasÄ±lÄ±ÄŸÄ± hesapla
                    final_prediction = 0.0
                    model_for_importance = None
                    
                    active_models = list(final_prediction_probas.keys())
                    with log_expander:
                        st.info(f"-> {stock_symbol}: Nihai olasÄ±lÄ±k hesaplanacak modeller: {active_models}")

                    if model_name == "Ensemble" and len(final_prediction_probas) > 1:
                        final_prediction = np.mean(list(final_prediction_probas.values()))
                        model_for_importance = trained_models.get(active_models[0])
                    elif model_name == "Hibrit Model" and len(final_prediction_probas) > 1:
                         weights_final = [0.4, 0.35, 0.25][:len(final_prediction_probas)]
                         probas_final = [final_prediction_probas[name] for name in active_models] # SÄ±rayÄ± koru
                         if len(probas_final) == len(weights_final):
                            final_prediction = np.average(probas_final, weights=weights_final)
                         else: 
                            final_prediction = np.mean(probas_final)
                         model_for_importance = trained_models.get(active_models[0])
                    elif model_name in final_prediction_probas:
                        final_prediction = final_prediction_probas[model_name]
                        model_for_importance = trained_models.get(model_name)
                    elif final_prediction_probas:
                        first_model_name = active_models[0]
                        final_prediction = final_prediction_probas[first_model_name]
                        model_for_importance = trained_models.get(first_model_name)
                        with log_expander:
                            st.warning(f"-> {stock_symbol}: SeÃ§ilen model ({model_name}) tahmin Ã¼retemedi, fallback: {first_model_name}")

                    with log_expander:
                        st.info(f"-> {stock_symbol}: Nihai Hesaplanan OlasÄ±lÄ±k: {final_prediction:.4f}")

                    # Ã–zellik Ã¶nemini al (eÄŸer model destekliyorsa)
                    feature_importance_values = {}
                    if feature_importance and model_for_importance and hasattr(model_for_importance, 'feature_importances_'):
                         importances = model_for_importance.feature_importances_
                         if len(features_to_use) == len(importances):
                             feature_importance_values = dict(zip(features_to_use, importances))
                         else:
                             with log_expander:
                                 st.warning(f"{stock_symbol}: Ã–zellik sayÄ±sÄ± ({len(features_to_use)}) ve Ã¶nem sayÄ±sÄ± ({len(importances)}) eÅŸleÅŸmiyor.")

                    # 12. Sinyal OluÅŸtur ve SonuÃ§larÄ± Kaydet
                    # GERÃ‡EK ZAMANLI FÄ°YAT KONTROLÃœ - ESKÄ° CACHE DEÄERLERÄ°NE GÃœVENME!
                    try:
                        import yfinance as yf
                        # AnlÄ±k fiyatÄ± direkt yfinance'den al (cache'e gÃ¼venme)
                        stock_ticker = yf.Ticker(stock_symbol)
                        
                        # Ä°lk Ã¶nce fast_info ile dene
                        try:
                            fast_info = stock_ticker.fast_info
                            if hasattr(fast_info, 'last_price') and fast_info.last_price is not None:
                                current_price = fast_info.last_price
                                with log_expander:
                                    st.success(f"-> {stock_symbol}: AnlÄ±k fiyat (fast_info): {current_price:.2f} TL")
                            else:
                                raise Exception("fast_info kullanÄ±lamadÄ±")
                        except:
                            # fast_info Ã§alÄ±ÅŸmazsa info ile dene
                            info = stock_ticker.info
                            current_price = None
                            
                            for key in ['regularMarketPrice', 'currentPrice', 'previousClose']:
                                if key in info and info[key] is not None and info[key] > 0:
                                    current_price = info[key]
                                    with log_expander:
                                        st.success(f"-> {stock_symbol}: AnlÄ±k fiyat ({key}): {current_price:.2f} TL")
                                    break
                            
                            # Hala bulunamadÄ±ysa veri setinden al
                            if current_price is None:
                                current_price = stock_data.iloc[-1]['Close']
                                with log_expander:
                                    st.warning(f"-> {stock_symbol}: AnlÄ±k fiyat alÄ±namadÄ±, veri setindeki son deÄŸer kullanÄ±lÄ±yor: {current_price:.2f} TL")
                    except Exception as price_e:
                        # Hata durumunda veri setindeki deÄŸeri kullan
                        current_price = stock_data.iloc[-1]['Close']
                        with log_expander:
                            st.warning(f"-> {stock_symbol}: AnlÄ±k fiyat hatasÄ± ({str(price_e)}), veri setindeki deÄŸer kullanÄ±lÄ±yor: {current_price:.2f} TL")
                    # Beklenen fiyatÄ± deterministik olarak hesapla
                    # Threshold ve olasÄ±lÄ±ÄŸa gÃ¶re sabit bir artÄ±ÅŸ hesapla
                    symbol_clean = stock_symbol.replace(".IS", "")
                    symbol_hash = sum(ord(c) for c in symbol_clean)
                    
                    # Deterministik artÄ±ÅŸ katsayÄ±sÄ± (threshold'a gÃ¶re)
                    base_increase = ml_threshold  # Minimum artÄ±ÅŸ threshold kadar
                    # OlasÄ±lÄ±ÄŸa gÃ¶re ek artÄ±ÅŸ (deterministik)
                    probability_factor = final_prediction * 2.0  # 0-2 arasÄ±
                    # Sembol bazlÄ± sabit faktÃ¶r
                    symbol_factor = ((symbol_hash % 100) / 100) * 0.5  # 0-0.5 arasÄ±
                    
                    total_increase = base_increase + (base_increase * probability_factor) + (base_increase * symbol_factor)
                    beklenen_fiyat = current_price * (1 + total_increase)
                    confidence_threshold_norm = confidence_threshold / 100.0

                    signal = "NÃ¶tr"
                    signal_color = "gray"

                    with log_expander:
                        st.info(f"-> {stock_symbol}: Sinyal kontrolÃ¼: OlasÄ±lÄ±k ({final_prediction:.4f}) > EÅŸik ({confidence_threshold_norm:.4f}) ?")

                    if final_prediction > confidence_threshold_norm:
                        signal = "YÃ¼kseliÅŸ"
                        signal_color = "green"
                        with log_expander:
                            st.info(f"-> {stock_symbol}: Sinyal: YÃœKSELÄ°Å")
                    else:
                         with log_expander:
                             st.info(f"-> {stock_symbol}: Sinyal: NÃ–TR (OlasÄ±lÄ±k eÅŸiÄŸi aÅŸmadÄ±)")

                    prediction_results.append({
                        "Hisse": stock_symbol.replace(".IS", ""),
                        "Mevcut Fiyat": current_price,
                        "Beklenen Fiyat": beklenen_fiyat,
                        "Tahmin OlasÄ±lÄ±ÄŸÄ±": final_prediction,
                        "Sinyal": signal,
                        "Sinyal Rengi": signal_color,
                        "Model": model_name,
                        "feature_importance": feature_importance_values,
                    })

                    # --- TAHMÄ°NÄ° VERÄ°TABANINA KAYDET ---
                    try:
                        save_ml_prediction(
                            symbol=stock_symbol.replace(".IS", ""),
                            current_price=current_price,
                            prediction_percentage=(beklenen_fiyat - current_price) / current_price if beklenen_fiyat and not pd.isna(beklenen_fiyat) else 0,
                            confidence_score=final_prediction,
                            prediction_result=signal,
                            model_type=model_name,
                            features_used=features_to_use,
                            target_date=(datetime.datetime.now() + datetime.timedelta(days=days_to_predict)).strftime("%Y-%m-%d %H:%M:%S")
                        )
                        with log_expander:
                            st.success(f"Tahmin veritabanÄ±na kaydedildi: {stock_symbol}")
                    except Exception as e:
                        with log_expander:
                            st.error(f"VeritabanÄ±na kayÄ±t hatasÄ±: {str(e)}")

                except Exception as loop_e:
                    with log_expander:
                        st.error(f"{stock_symbol} iÅŸlenirken beklenmedik HATA: {str(loop_e)}")
                        st.error(traceback.format_exc())

            # --- DÃ¶ngÃ¼ Sonu ---
            with log_expander:
                st.info("[LOG] Hisse senedi iÅŸleme dÃ¶ngÃ¼sÃ¼ tamamlandÄ±.")
                st.info(f"[Ã–ZET] Toplam {len(prediction_results)} hisse iÃ§in sonuÃ§ Ã¼retildi (sinyal fark etmeksizin).")
            if not prediction_results:
                 with log_expander:
                     st.warning("[Ã–ZET] HiÃ§bir hisse iÃ§in sonuÃ§ Ã¼retilemedi.")
                 result_container.warning("HiÃ§bir hisse iÃ§in sonuÃ§ Ã¼retilemedi.")
            else:
                 rising_stocks_final_check = [r for r in prediction_results if r["Sinyal"] == "YÃ¼kseliÅŸ"]
                 if not rising_stocks_final_check:
                     with log_expander:
                         st.warning("[Ã–ZET] SonuÃ§lar Ã¼retildi ancak hiÃ§biri 'YÃ¼kseliÅŸ' sinyali vermedi (olasÄ±lÄ±k eÅŸiÄŸi aÅŸÄ±lmadÄ±?).")
                     result_container.warning("SonuÃ§lar Ã¼retildi ancak hiÃ§biri 'YÃ¼kseliÅŸ' sinyali vermedi (olasÄ±lÄ±k eÅŸiÄŸi aÅŸÄ±lmadÄ±?).")
                 else:
                     with log_expander:
                         st.info(f"[Ã–ZET] {len(rising_stocks_final_check)} hisse 'YÃ¼kseliÅŸ' sinyali verdi.")

            # Ä°ÅŸlem tamamlandÄ± mesajÄ±
            with log_expander:
                st.info("Tarama tamamlandÄ±! SonuÃ§lar iÅŸleniyor...")
            
            # Ä°lerleme Ã§ubuÄŸunu tamamla (eÄŸer tanÄ±mlanmÄ±ÅŸsa)
            if 'progress_bar' in locals() or 'progress_bar' in globals():
                progress_bar.progress(1.0)

            # 13. SonuÃ§larÄ± GÃ¶ster
            if prediction_results:
                prediction_results.sort(key=lambda x: x["Tahmin OlasÄ±lÄ±ÄŸÄ±"], reverse=True)
                rising_stocks = [r for r in prediction_results if r["Sinyal"] == "YÃ¼kseliÅŸ"]

                if rising_stocks:
                    try:
                        with log_expander:
                            st.info(f"**{len(rising_stocks)}** hisse iÃ§in '{time_frame}' periyodunda **%{ml_threshold*100:.1f} Ã¼zeri yÃ¼kseliÅŸ potansiyeli** (OlasÄ±lÄ±k > {confidence_threshold}%) bulundu:")
                        
                        # Ana ekranda potansiyel yÃ¼kseliÅŸleri gÃ¶ster
                        result_container.markdown("## ğŸ“ˆ Potansiyel YÃ¼kseliÅŸ Sinyalleri")
                        result_container.markdown(f"**{len(rising_stocks)}** hisse iÃ§in '{time_frame}' periyodunda **%{ml_threshold*100:.1f} Ã¼zeri yÃ¼kseliÅŸ potansiyeli** (OlasÄ±lÄ±k > {confidence_threshold}%) bulundu:")
                        rising_list = ", ".join([f"**{r['Hisse']}**" for r in rising_stocks])
                        result_container.markdown(f"YÃ¼kseliÅŸ sinyali veren hisseler: {rising_list}")

                        # BasitleÅŸtirilmiÅŸ tablo gÃ¶sterimi - Daha gÃ¼venilir hale getirildi
                        try:
                            result_df_rising = pd.DataFrame(rising_stocks)
                            
                            # Gerekli kolonlarÄ±n varlÄ±ÄŸÄ±nÄ± kontrol et
                            required_cols = ["Hisse", "Tahmin OlasÄ±lÄ±ÄŸÄ±"]
                            missing_cols = [col for col in required_cols if col not in result_df_rising.columns]
                            
                            if missing_cols:
                                raise ValueError(f"Gerekli kolonlar eksik: {missing_cols}")
                                
                            # Veriyi hazÄ±rla - GÃ¼venli bir ÅŸekilde
                            result_df = result_df_rising.copy()
                            
                            # BoÅŸ veya NaN deÄŸerleri temizle
                            result_df = result_df.dropna(subset=["Hisse", "Tahmin OlasÄ±lÄ±ÄŸÄ±"])
                            
                            if len(result_df) == 0:
                                raise ValueError("GeÃ§erli veri bulunamadÄ±")
                            
                            # OlasÄ±lÄ±ÄŸÄ± yÃ¼zde formatÄ±na Ã§evir - GÃ¼venli 
                            result_df["YÃ¼kseliÅŸ OlasÄ±lÄ±ÄŸÄ± (%)"] = (result_df["Tahmin OlasÄ±lÄ±ÄŸÄ±"] * 100).round(2)
                            
                            # Temel gÃ¶sterim tablosu oluÅŸtur
                            display_data = []
                            
                            for idx, row in result_df.iterrows():
                                try:
                                    hisse_kodu = str(row["Hisse"]).strip()
                                    olasÄ±lÄ±k = float(row["YÃ¼kseliÅŸ OlasÄ±lÄ±ÄŸÄ± (%)"])
                                    
                                    # Mevcut fiyat kontrolÃ¼
                                    mevcut_fiyat = row.get("Mevcut Fiyat", 0)
                                    if pd.isna(mevcut_fiyat) or mevcut_fiyat <= 0:
                                        mevcut_fiyat = 0.0
                                    
                                    # Model bilgisi kontrolÃ¼
                                    model = row.get("Model", "Bilinmiyor")
                                    if pd.isna(model):
                                        model = "Bilinmiyor"
                                    
                                    # Sinyal kontrolÃ¼
                                    sinyal = row.get("Sinyal", "YÃ¼kseliÅŸ")
                                    if pd.isna(sinyal):
                                        sinyal = "YÃ¼kseliÅŸ"
                                    
                                    # Basit tahmini artÄ±ÅŸ hesaplama
                                    beklenen_artis = (ml_threshold * 100) * (olasÄ±lÄ±k / 100)  # OlasÄ±lÄ±ÄŸa gÃ¶re Ã¶lÃ§eklendir
                                    beklenen_fiyat = mevcut_fiyat * (1 + beklenen_artis / 100) if mevcut_fiyat > 0 else 0.0
                                    
                                    display_data.append({
                                        "Hisse Kodu": hisse_kodu,
                                        "Mevcut Fiyat (â‚º)": round(float(mevcut_fiyat), 2),
                                        "Beklenen Fiyat (â‚º)": round(beklenen_fiyat, 2),
                                        "Tahmini ArtÄ±ÅŸ (%)": round(beklenen_artis, 2),
                                        "YÃ¼kseliÅŸ OlasÄ±lÄ±ÄŸÄ± (%)": round(olasÄ±lÄ±k, 2),
                                        "Sinyal": str(sinyal),
                                        "Model": str(model)
                                    })
                                    
                                except Exception as row_error:
                                    with log_expander:
                                        st.warning(f"SatÄ±r iÅŸleme hatasÄ±: {row_error}")
                                    continue
                            
                            if not display_data:
                                raise ValueError("GÃ¶sterilecek geÃ§erli veri bulunamadÄ±")
                            
                            # DataFrame oluÅŸtur
                            final_df = pd.DataFrame(display_data)
                            
                            # SÃ¼tun sÄ±rasÄ±nÄ± ayarla
                            column_order = ["Hisse Kodu", "Mevcut Fiyat (â‚º)", "Beklenen Fiyat (â‚º)", 
                                            "Tahmini ArtÄ±ÅŸ (%)", "YÃ¼kseliÅŸ OlasÄ±lÄ±ÄŸÄ± (%)", 
                                            "Sinyal", "Model"]
                            
                            # Sadece mevcut sÃ¼tunlarÄ± kullan
                            available_cols = [col for col in column_order if col in final_df.columns]
                            final_df = final_df[available_cols]
                            
                            # Tabloya baÅŸlÄ±k ekle
                            result_container.markdown("### ğŸ” Hisse YÃ¼kseliÅŸ Tahminleri")
                            
                            # Tabloyu gÃ¶ster
                            result_container.dataframe(
                                final_df,
                                use_container_width=True,
                                hide_index=True,
                            )
                            
                            # Tablonun altÄ±na aÃ§Ä±klama ekle
                            result_container.markdown("""
                            **Tablo AÃ§Ä±klamalarÄ±:**
                            - **Mevcut Fiyat (â‚º)**: Hissenin mevcut fiyatÄ± (tahmin zamanÄ±ndaki)
                            - **Beklenen Fiyat (â‚º)**: Tahmin edilen dÃ¶nem sonundaki hedef fiyat
                            - **Tahmini ArtÄ±ÅŸ (%)**: Modelin tahmin ettiÄŸi yÃ¼kseliÅŸ yÃ¼zdesi 
                            - **YÃ¼kseliÅŸ OlasÄ±lÄ±ÄŸÄ± (%)**: Modelin belirlenen eÅŸikten fazla yÃ¼kseleceÄŸine olan gÃ¼ven dÃ¼zeyi
                            - **Model**: Tahmini yapan makine Ã¶ÄŸrenmesi modeli
                            """)
                        
                        except Exception as tablo_hata:
                            with log_expander:
                                st.error(f"Tablo oluÅŸturulurken hata oluÅŸtu: {tablo_hata}")
                                st.error(traceback.format_exc())
                            # Tablo oluÅŸturma hatasÄ± olsa bile kullanÄ±cÄ±ya basit liste gÃ¶sterelim
                            result_container.warning("âš ï¸ DetaylÄ± tablo oluÅŸturulamadÄ±. Basit liste:")
                            
                            # En basit haliyle bilgileri listeleyelim
                            for stock in rising_stocks:
                                olasÄ±lÄ±k = stock.get("Tahmin OlasÄ±lÄ±ÄŸÄ±", 0) * 100
                                fiyat = stock.get("Mevcut Fiyat", 0)
                                result_container.info(f"**{stock['Hisse']}**: Mevcut Fiyat: {fiyat:.2f} â‚º, YÃ¼kseliÅŸ OlasÄ±lÄ±ÄŸÄ±: %{olasÄ±lÄ±k:.2f}")
                        
                    except Exception as genel_hata:
                        with log_expander:
                            st.error(f"Tablo ve Ã¶zet gÃ¶steriminde genel hata: {genel_hata}")
                            st.error(traceback.format_exc())
                        # Hata olsa bile en azÄ±ndan hisse listesini gÃ¶ster
                        if rising_stocks:
                            result_container.warning("âš ï¸ DetaylÄ± gÃ¶sterim hatasÄ±. Bulunan hisseler:")
                            result_container.markdown(", ".join([r['Hisse'] for r in rising_stocks]))
                else:
                    with log_expander:
                        st.warning(f"Belirtilen kriterlere (eÅŸik > %{ml_threshold*100:.1f}, olasÄ±lÄ±k > {confidence_threshold}%) gÃ¶re potansiyel yÃ¼kseliÅŸ beklenen hisse bulunamadÄ±.")
                        st.info("Daha dÃ¼ÅŸÃ¼k eÅŸik deÄŸeri veya olasÄ±lÄ±k yÃ¼zdesi seÃ§meyi deneyebilirsiniz.")
                    
                    # Ana ekranda uyarÄ± gÃ¶ster
                    result_container.warning(f"Belirtilen kriterlere (eÅŸik > %{ml_threshold*100:.1f}, olasÄ±lÄ±k > {confidence_threshold}%) gÃ¶re potansiyel yÃ¼kseliÅŸ beklenen hisse bulunamadÄ±.")
                    result_container.info("Daha dÃ¼ÅŸÃ¼k eÅŸik deÄŸeri veya olasÄ±lÄ±k yÃ¼zdesi seÃ§meyi deneyebilirsiniz.")

                # Geriye dÃ¶nÃ¼k test sonuÃ§larÄ±
                if backtesting and backtesting_results_list:
                     with log_expander:
                         st.info("Geriye DÃ¶nÃ¼k Test SonuÃ§larÄ± (Test Seti PerformansÄ±):")
                     bt_df = pd.DataFrame(backtesting_results_list)
                     for col in ["DoÄŸruluk", "Kesinlik", "DuyarlÄ±lÄ±k", "F1 Skoru"]:
                          if col in bt_df.columns:
                              bt_df[col] = bt_df[col].apply(lambda x: f"{x*100:.1f}%" if pd.notnull(x) and np.isfinite(x) else "N/A")
                     with log_expander:
                         st.info(bt_df.to_string())
                         st.info("""**Metrikler:** **DoÄŸruluk:** Genel baÅŸarÄ±. **Kesinlik:** 'YÃ¼kseliÅŸ' tahminlerinin doÄŸruluÄŸu. **DuyarlÄ±lÄ±k:** GerÃ§ek yÃ¼kseliÅŸleri yakalama oranÄ±. **F1:** Kesinlik ve DuyarlÄ±lÄ±ÄŸÄ±n dengesi.""")
                     
                     # Ana ekranda geriye dÃ¶nÃ¼k test sonuÃ§larÄ±nÄ± daha estetik gÃ¶ster
                     result_container.markdown("### ğŸ“Š Geriye DÃ¶nÃ¼k Test SonuÃ§larÄ±")
                     
                     # Veriyi tablo olarak daha gÃ¼zel gÃ¶ster
                     bt_df_reset = bt_df.reset_index()
                     
                     bt_html_table = "<table style='width:100%; border-collapse:collapse; margin-top:10px; margin-bottom:20px;'>"
                     
                     # Tablo baÅŸlÄ±klarÄ±
                     bt_html_table += "<tr style='background-color:#f0f2f6; font-weight:bold;'>"
                     bt_html_table += "<th style='padding:12px; text-align:left; border-bottom:2px solid #ccc;'>Hisse-Model</th>"
                     bt_html_table += "<th style='padding:12px; text-align:center; border-bottom:2px solid #ccc;'>DoÄŸruluk</th>"
                     bt_html_table += "<th style='padding:12px; text-align:center; border-bottom:2px solid #ccc;'>Kesinlik</th>"
                     bt_html_table += "<th style='padding:12px; text-align:center; border-bottom:2px solid #ccc;'>DuyarlÄ±lÄ±k</th>"
                     bt_html_table += "<th style='padding:12px; text-align:center; border-bottom:2px solid #ccc;'>F1 Skoru</th>"
                     bt_html_table += "</tr>"
                     
                     # KÄ±saltÄ±lmÄ±ÅŸ tabloda sadece ilk 50 satÄ±rÄ± gÃ¶ster (Ã§ok fazla kayÄ±t varsa)
                     max_rows = min(50, len(bt_df_reset))
                     
                     # Tablo iÃ§eriÄŸi
                     for idx, row in bt_df_reset.head(max_rows).iterrows():
                         bt_html_table += "<tr>"
                         
                         # Hisse-Model
                         hisse_model = row['Hisse-Model']
                         hisse_code = hisse_model.split('-')[0].replace('.IS', '') if '-' in hisse_model else hisse_model
                         model_name = hisse_model.split('-')[1] if '-' in hisse_model else ""
                         
                         bt_html_table += f"<td style='padding:10px; border-bottom:1px solid #ddd;'><span style='font-weight:bold;'>{hisse_code}</span> - {model_name}</td>"
                         
                         # Metrikleri renklendir
                         for col in ["DoÄŸruluk", "Kesinlik", "DuyarlÄ±lÄ±k", "F1 Skoru"]:
                             try:
                                 # YÃ¼zde deÄŸerini al
                                 val_str = row[col]
                                 val = float(val_str.replace('%', ''))
                                 
                                 # DeÄŸere gÃ¶re renklendirme
                                 if val >= 80:
                                     cell_color = "rgba(0, 128, 0, 0.2)"
                                     text_color = "darkgreen"
                                     font_weight = "bold"
                                 elif val >= 60:
                                     cell_color = "rgba(0, 128, 0, 0.1)"
                                     text_color = "green"
                                     font_weight = "normal"
                                 elif val >= 40:
                                     cell_color = "rgba(255, 165, 0, 0.1)"
                                     text_color = "darkorange"
                                     font_weight = "normal"
                                 elif val > 0:
                                     cell_color = "rgba(255, 0, 0, 0.05)"
                                     text_color = "darkred" 
                                     font_weight = "normal"
                                 else:
                                     cell_color = "white"
                                     text_color = "gray"
                                     font_weight = "normal"
                                     
                                 bt_html_table += f"<td style='padding:10px; border-bottom:1px solid #ddd; text-align:center; background-color:{cell_color}; color:{text_color}; font-weight:{font_weight};'>{val_str}</td>"
                             except:
                                 bt_html_table += f"<td style='padding:10px; border-bottom:1px solid #ddd; text-align:center;'>{row[col]}</td>"
                         
                         bt_html_table += "</tr>"
                     
                     # EÄŸer Ã§ok fazla sonuÃ§ varsa not ekle
                     if len(bt_df_reset) > max_rows:
                         bt_html_table += f"<tr><td colspan='5' style='padding:10px; text-align:center; font-style:italic;'>Toplam {len(bt_df_reset)} sonuÃ§tan ilk {max_rows} tanesi gÃ¶steriliyor</td></tr>"
                     
                     bt_html_table += "</table>"
                     
                     # HTML tabloyu gÃ¶ster
                     result_container.markdown(bt_html_table, unsafe_allow_html=True)
                     
                     # Metrik aÃ§Ä±klamalarÄ±
                     result_container.markdown("""
                     <div style='background-color:#f9f9f9; padding:10px; border-radius:5px; border-left:4px solid #4682B4; margin-top:10px;'>
                     <p style='margin:0; font-weight:bold;'>ğŸ“Œ Metrik AÃ§Ä±klamalarÄ±:</p>
                     <ul style='margin-top:5px; margin-bottom:0;'>
                         <li><b>DoÄŸruluk:</b> Modelin genel tahmin baÅŸarÄ±sÄ±</li>
                         <li><b>Kesinlik:</b> 'YÃ¼kseliÅŸ' olarak tahmin edilenlerin gerÃ§ekten yÃ¼kseliÅŸ gÃ¶sterme oranÄ±</li>
                         <li><b>DuyarlÄ±lÄ±k:</b> GerÃ§ekte yÃ¼kseliÅŸ gÃ¶steren hisseleri doÄŸru tespit etme oranÄ±</li>
                         <li><b>F1 Skoru:</b> Kesinlik ve duyarlÄ±lÄ±ÄŸÄ±n harmonik ortalamasÄ±</li>
                     </ul>
                     </div>
                     """, unsafe_allow_html=True)

                # Ã–zellik Ã–nemi
                if feature_importance and prediction_results:
                    with log_expander:
                        st.info(f"Ortalama Ã–zellik Ã–nemi ({model_name}):")
                    all_importances = {}
                    valid_imp_count = 0
                    for res in prediction_results:
                        imp = res.get("feature_importance")
                        if imp:
                            valid_imp_count += 1
                            for feat, val in imp.items():
                                if pd.notnull(val) and np.isfinite(val):
                                    all_importances[feat] = all_importances.get(feat, 0) + val

                    if valid_imp_count > 0:
                        avg_importances = {feat: val / valid_imp_count for feat, val in all_importances.items()}
                        sorted_importances = sorted(avg_importances.items(), key=lambda item: item[1], reverse=True)
                        top_n = min(20, len(sorted_importances))
                        features_plot = [item[0] for item in sorted_importances[:top_n]]
                        values_plot = [item[1] for item in sorted_importances[:top_n]]

                        if features_plot:
                            try:
                                fig, ax = plt.subplots(figsize=(10, max(5, len(features_plot) * 0.3)))
                                ax.barh(features_plot[::-1], values_plot[::-1])
                                ax.set_xlabel("Ortalama Ã–nem PuanÄ±")
                                ax.set_title(f"En Ã–nemli {top_n} Ã–zellik ({model_name} iÃ§in Ortalama)")
                                plt.tight_layout()
                                with log_expander:
                                    st.info(f"Ã–zellik Ã¶nemi grafiÄŸi oluÅŸturuldu: {fig}")
                                
                                # Ana ekranda grafiÄŸi gÃ¶ster
                                result_container.subheader(f"Ortalama Ã–zellik Ã–nemi ({model_name})")
                                result_container.pyplot(fig)
                                
                                plt.close(fig)
                            except Exception as plot_e:
                                with log_expander:
                                    st.warning(f"Ã–zellik Ã¶nemi grafiÄŸi hatasÄ±: {plot_e}")
                        else: 
                            with log_expander:
                                st.info("GÃ¶sterilecek Ã¶zellik Ã¶nemi verisi yok.")
                    else: 
                        with log_expander:
                            st.info("Ã–zellik Ã¶nemi hesaplanamadÄ± veya bulunamadÄ±.")

                # Tarama Ã¶zeti (log dosyasÄ±)
                successful_stocks = len(prediction_results)
                failed_stocks = total_stocks - successful_stocks
                with log_expander:
                    st.info(f"Tarama Ä°statistikleri: Toplam {total_stocks} hisse incelendi")
                    st.info(f"BaÅŸarÄ±yla analiz edildi: {successful_stocks}, BaÅŸarÄ±sÄ±z: {failed_stocks}")
                
                # Ana ekranda Ã¶zet gÃ¶ster
                result_container.markdown("## ğŸ“Š Tarama Ä°statistikleri")
                result_container.markdown(f"**Toplam {total_stocks} hisse incelendi**")
                result_container.markdown(f"âœ… BaÅŸarÄ±yla analiz edildi: **{successful_stocks}** | âŒ BaÅŸarÄ±sÄ±z: **{failed_stocks}**")
                
                if rising_stocks:
                    with log_expander:
                        st.info(f"Potansiyel YÃ¼kseliÅŸ Sinyali Veren Hisseler: {', '.join([r['Hisse'] for r in rising_stocks])}")
                    
                    # Ana ekranda potansiyel yÃ¼kseliÅŸleri gÃ¶ster
                    result_container.success(f"Potansiyel YÃ¼kseliÅŸ Sinyali Veren Hisseler: {', '.join([r['Hisse'] for r in rising_stocks])}")
                else:
                    with log_expander:
                        st.warning("Potansiyel yÃ¼kseliÅŸ sinyali veren hisse bulunamadÄ±.")
                    
                    result_container.warning("Potansiyel yÃ¼kseliÅŸ sinyali veren hisse bulunamadÄ±.")

            else:
                with log_expander:
                    st.warning("Tarama sonucunda iÅŸlenecek geÃ§erli bir hisse bulunamadÄ±.")
                    st.info("Tarama kriterlerini deÄŸiÅŸtirerek yeniden deneyebilirsiniz.")
                    st.error("HiÃ§bir hisse baÅŸarÄ±yla iÅŸlenemedi.")
                
                # Ana ekranda hata mesajÄ± gÃ¶ster
                result_container.error("Tarama sonucunda iÅŸlenecek geÃ§erli bir hisse bulunamadÄ±.")
                result_container.info("Tarama kriterlerini deÄŸiÅŸtirerek yeniden deneyebilirsiniz.")
                result_container.error("HiÃ§bir hisse baÅŸarÄ±yla iÅŸlenemedi.")

        except MemoryError:
            with log_expander:
                st.error("Bellek HatasÄ±! Sistem belleÄŸi tarama iÃ§in yetersiz kaldÄ±. Daha az hisse seÃ§in veya daha kÄ±sa periyot deneyin.")
            
            # Ana ekranda bellek hatasÄ± gÃ¶ster
            result_container.error("Bellek HatasÄ±! Sistem belleÄŸi tarama iÃ§in yetersiz kaldÄ±. Daha az hisse seÃ§in veya daha kÄ±sa periyot deneyin.")

# VeritabanÄ± iÅŸlemleri iÃ§in importlarÄ± ekle
import sqlite3
try:
    from data.db_utils import (
        save_ml_prediction, 
        get_ml_predictions, 
        update_ml_prediction_result,
        get_ml_prediction_stats,
        DB_FILE
    )
except ImportError as e:
    import os
    from pathlib import Path
    
    # Ana repo dizinini bul ve sys.path'e ekle
    current_dir = os.path.dirname(os.path.abspath(__file__))
    parent_dir = os.path.dirname(current_dir)
    
    import sys
    if parent_dir not in sys.path:
        sys.path.append(parent_dir)
    
    # Ä°mportlarÄ± tekrar dene
    from data.db_utils import (
        save_ml_prediction, 
        get_ml_predictions, 
        update_ml_prediction_result,
        get_ml_prediction_stats,
        DB_FILE
    )

# ... Var olan kod devam edecek ...

# process_ml_prediction fonksiyonuna veritabanÄ± kaydÄ± ekliyorum
# Tahmin kÄ±smÄ±nÄ±n sonunda, st.dataframe'den sonra ekle (yaklaÅŸÄ±k 1750-2000 satÄ±r arasÄ±nda)

# Bu fonksiyon iÃ§inde uygun yere eklenmeli - sonuÃ§larÄ±n gÃ¶sterildiÄŸi bÃ¶lÃ¼mden sonra
# Ä°lgili fonksiyonu bulup bu kodu ekliyoruz:

def process_ml_prediction(params, log_expander=None, result_container=None):
    # ... mevcut kodlar ...
    
    # SonuÃ§lar gÃ¶sterildikten sonra aÅŸaÄŸÄ±daki kodu ekleyin, display_message deÄŸiÅŸkeni varsa ondan sonra:
    
    # Var olan kodlar...
    
    # Tahmin sonuÃ§larÄ±nÄ± veritabanÄ±na kaydet - Bu kodu doÄŸru girintiyle mevcut fonksiyonun iÃ§ine yerleÅŸtirin
    if 'predictions_df' in params and len(params['predictions_df']) > 0:
        predictions_df = params['predictions_df']
        time_frame = params.get('time_frame', '1 GÃ¼n')
        model_type = params.get('model_type', 'LightGBM')
        all_features = params.get('all_features', [])
        days_prediction = params.get('days_prediction', 30)  # KullanÄ±cÄ±nÄ±n seÃ§tiÄŸi tahmin gÃ¼n sayÄ±sÄ±
        
        try:
            # DB utils import - burada doÄŸrudan import kullan
            import sys
            import os
            from pathlib import Path
            
            # Ana repo dizinini bul ve sys.path'e ekle
            current_dir = os.path.dirname(os.path.abspath(__file__))
            parent_dir = os.path.dirname(current_dir)
            
            if parent_dir not in sys.path:
                sys.path.append(parent_dir)
            
            from data.db_utils import (
                save_ml_prediction, 
                get_ml_predictions, 
                update_ml_prediction_result,
                get_ml_prediction_stats,
                DB_FILE
            )
            
            # Her hisse iÃ§in tahmin sonucunu kaydet
            for _, row in predictions_df.iterrows():
                symbol = row['Hisse']
                prediction_pct = float(row['YÃ¼kseliÅŸ Tahmini'].strip('%')) / 100
                confidence = float(row['OlasÄ±lÄ±k'].strip('%')) / 100
                current_price = float(row['Mevcut Fiyat'])
                
                # Hedef tarihi kullanÄ±cÄ±nÄ±n seÃ§tiÄŸi gÃ¼n sayÄ±sÄ±na gÃ¶re ayarla
                target_date = datetime.datetime.now() + datetime.timedelta(days=days_prediction)
                target_date_str = target_date.strftime("%Y-%m-%d %H:%M:%S")
                
                # KullanÄ±lan Ã¶zellik listesini oluÅŸtur
                features_used = all_features
                
                # ML tahmin sonucunu kaydet
                save_ml_prediction(
                    symbol=symbol,
                    current_price=current_price,
                    prediction_percentage=prediction_pct,
                    confidence_score=confidence,  # 0-1 arasÄ±nda kaydet
                    prediction_result="YUKARI", 
                    model_type=model_type,
                    features_used=features_used,
                    target_date=target_date_str
                )
                
                if log_expander is not None:
                    with log_expander:
                        st.success(f"Tahmin veritabanÄ±na kaydedildi: {symbol}")
                
            if 'ml_predictions_saved' not in st.session_state:
                st.session_state.ml_predictions_saved = True
                
            if result_container is not None:
                result_container.success("âœ… Tahmin sonuÃ§larÄ± veritabanÄ±na kaydedildi!")
                
        except Exception as db_error:
            import traceback
            error_details = traceback.format_exc()
            
            if log_expander is not None:
                with log_expander:
                    st.error(f"Tahmin kaydedilirken hata: {str(db_error)}")
                    st.code(error_details)
            
            if result_container is not None:
                result_container.error(f"âŒ Tahmin veritabanÄ±na kaydedilemedi: {str(db_error)}")
    
    # Var olan kod devam eder...

# MLResultsHistoryTab fonksiyonu - dosyanÄ±n en sonuna eklenecek
def render_ml_results_history_tab():
    """
    ML tahmin geÃ§miÅŸi sekmesini gÃ¶rÃ¼ntÃ¼ler
    """
    st.header("ML Tahmin GeÃ§miÅŸi ğŸ“Š", divider="rainbow")
    
    # Genel istatistikleri gÃ¶ster
    stats = get_ml_prediction_stats()
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Toplam Tahmin", f"{stats['total_predictions']}")
    
    with col2:
        st.metric("DoÄŸrulanmÄ±ÅŸ Tahmin", f"{stats['verified_predictions']}")
    
    with col3:
        st.metric("DoÄŸru Tahmin", f"{stats['correct_predictions']}")
    
    with col4:
        st.metric("BaÅŸarÄ± OranÄ±", f"{stats['success_rate']:.1f}%")
    
    st.markdown(f"**En BaÅŸarÄ±lÄ± Model:** {stats['best_model']}")
    
    # Filtreleme seÃ§enekleri
    filter_col1, filter_col2, filter_col3 = st.columns(3)
    
    with filter_col1:
        symbol_filter = st.text_input("Hisse Filtrele", key="ml_history_symbol_filter")
    
    with filter_col2:
        include_verified = st.checkbox("DoÄŸrulanmÄ±ÅŸ Tahminleri Dahil Et", value=True, key="ml_history_include_verified")
    
    with filter_col3:
        limit = st.number_input("Maksimum GÃ¶sterilecek KayÄ±t", min_value=10, max_value=100, value=50, step=10, key="ml_history_limit")
    
    # Tahminleri getir
    predictions = get_ml_predictions(
        symbol=symbol_filter if symbol_filter else None,
        limit=limit,
        include_verified=include_verified
    )
    
    if not predictions:
        st.info("KayÄ±tlÄ± ML tahmin sonucu bulunamadÄ±.")
        return
    
    # Dataframe oluÅŸtur
    df_data = []
    
    for pred in predictions:
        was_correct_map = {-1: "Beklemede", 0: "âŒ YanlÄ±ÅŸ", 1: "âœ… DoÄŸru"}
        
        row = {
            "ID": pred["id"],
            "Hisse": pred["symbol"],
            "Tarih": pred["prediction_date"],
            "Hedef Tarih": pred["target_date"] if pred["target_date"] else "BelirtilmemiÅŸ",
            "Fiyat": f"{pred['current_price']:.2f} â‚º",
            "Tahmin": f"{pred['prediction_percentage']*100:.1f}%",
            "GÃ¼ven": f"{pred['confidence_score']*100:.1f}%",
            "Model": pred["model_type"],
            "SonuÃ§": was_correct_map.get(pred["was_correct"], "Beklemede")
        }
        
        # GerÃ§ekleÅŸen sonuÃ§ varsa ekle
        if pred["actual_result"] is not None:
            row["GerÃ§ekleÅŸen"] = f"{pred['actual_result']*100:.1f}%"
        else:
            row["GerÃ§ekleÅŸen"] = "-"
            
        df_data.append(row)
    
    # DataFrame oluÅŸtur
    import pandas as pd
    history_df = pd.DataFrame(df_data)
    
    # Tabloyu gÃ¶ster
    st.dataframe(history_df, use_container_width=True)
    
    # Tahmin Sonucu DoÄŸrulama
    st.subheader("Tahmin Sonucu DoÄŸrulama")
    st.markdown("""
    GeÃ§miÅŸ bir tahminin gerÃ§ekleÅŸen sonucunu iÅŸaretlemek iÃ§in aÅŸaÄŸÄ±daki formu kullanÄ±n.
    DoÄŸrulama iÅŸlemi, modelin baÅŸarÄ± oranÄ±nÄ± takip etmenizi saÄŸlar.
    """)
    
    verify_col1, verify_col2, verify_col3 = st.columns(3)
    
    with verify_col1:
        prediction_id = st.number_input("Tahmin ID", min_value=1, step=1, key="verify_prediction_id")
    
    with verify_col2:
        actual_result = st.number_input("GerÃ§ekleÅŸen DeÄŸiÅŸim (%)", min_value=-100.0, max_value=100.0, step=0.1, key="verify_actual_result")
        actual_result = actual_result / 100  # YÃ¼zde deÄŸerini ondalÄ±k deÄŸere dÃ¶nÃ¼ÅŸtÃ¼r
    
    with verify_col3:
        was_correct = st.selectbox("Tahmin DoÄŸru muydu?", ["Evet", "HayÄ±r"], key="verify_was_correct")
        was_correct_value = 1 if was_correct == "Evet" else 0
    
    # DoÄŸrulama butonu
    if st.button("Tahmin Sonucunu Kaydet", key="verify_prediction_button"):
        try:
            success = update_ml_prediction_result(prediction_id, actual_result, was_correct_value)
            if success:
                st.success(f"Tahmin #{prediction_id} baÅŸarÄ±yla gÃ¼ncellendi.")
            else:
                st.error("Tahmin gÃ¼ncellenirken bir hata oluÅŸtu.")
        except Exception as e:
            st.error(f"Hata: {str(e)}")
            
    # Tahmin SonuÃ§ Grafikleri
    if stats['verified_predictions'] > 0:
        st.subheader("Tahmin Performans Analizi")
        
        graph_col1, graph_col2 = st.columns(2)
        
        with graph_col1:
            # BaÅŸarÄ± oranÄ± pasta grafiÄŸi
            import plotly.graph_objects as go
            labels = ['DoÄŸru Tahminler', 'YanlÄ±ÅŸ Tahminler']
            values = [stats['correct_predictions'], stats['verified_predictions'] - stats['correct_predictions']]
            
            fig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.4)])
            fig.update_layout(title_text="DoÄŸru/YanlÄ±ÅŸ Tahmin OranÄ±")
            st.plotly_chart(fig, use_container_width=True)
            
        with graph_col2:
            # Model baÅŸarÄ± grafiÄŸi
            try:
                conn = sqlite3.connect(DB_FILE)
                cursor = conn.cursor()
                
                # Her model iÃ§in baÅŸarÄ± oranÄ±nÄ± hesapla
                cursor.execute("""
                SELECT model_type, 
                       COUNT(*) as total,
                       SUM(CASE WHEN was_correct = 1 THEN 1 ELSE 0 END) as correct
                FROM ml_predictions
                WHERE was_correct != -1
                GROUP BY model_type
                """)
                
                model_stats = cursor.fetchall()
                conn.close()
                
                if model_stats:
                    model_names = [ms[0] for ms in model_stats]
                    success_rates = [ms[2]/ms[1]*100 if ms[1] > 0 else 0 for ms in model_stats]
                    
                    fig = go.Figure(data=[go.Bar(x=model_names, y=success_rates)])
                    fig.update_layout(title_text="Model BaÅŸarÄ± OranlarÄ± (%)", yaxis_range=[0, 100])
                    st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.error(f"Grafik oluÅŸturulurken hata: {str(e)}")

def create_future_prediction_chart(current_price, prediction_data, last_date):
    """
    Tahmin grafiÄŸi oluÅŸturur
    """
    try:
        # Tahmin verilerini al
        predicted_price = prediction_data.get('point_prediction', current_price * 1.05)
        lower_bound = prediction_data.get('lower_bound', current_price * 0.95)
        upper_bound = prediction_data.get('upper_bound', current_price * 1.15)
        days = prediction_data.get('days', 30)
        
        # Gelecek tarihleri manuel olarak liste olarak oluÅŸtur
        future_dates = []
        for i in range(1, days + 1):
            if isinstance(last_date, pd.Timestamp):
                future_dates.append(last_date + pd.Timedelta(days=i))
            else:
                future_dates.append(datetime.datetime.now() + datetime.timedelta(days=i))
                
        # Tahmin noktalarÄ±nÄ± oluÅŸtur
        y_pred = []
        y_lower = []
        y_upper = []
        
        for i in range(days):
            # DoÄŸrusal ilerleme
            progress = i / (days - 1) if days > 1 else 1
            
            # Merkez tahmin
            center_prediction = current_price + (predicted_price - current_price) * progress
            
            # Alt ve Ã¼st sÄ±nÄ±rlar
            lower_prediction = current_price + (lower_bound - current_price) * progress
            upper_prediction = current_price + (upper_bound - current_price) * progress
            
            # Rasgele gÃ¼rÃ¼ltÃ¼ ekle (gerÃ§ekÃ§ilik iÃ§in)
            noise = np.random.normal(0, 0.005 * current_price)
            
            y_pred.append(center_prediction + noise)
            y_lower.append(lower_prediction)
            y_upper.append(upper_prediction)
            
        # Grafik oluÅŸtur
        fig = go.Figure()
        
        # Tahmin Ã§izgisi
        fig.add_trace(go.Scatter(
            x=future_dates, 
            y=y_pred,
            mode='lines',
            name='ML Tahmini',
            line=dict(color='blue')
        ))
        
        # GÃ¼ven aralÄ±ÄŸÄ± - listeleri birleÅŸtirme sorununu Ã§Ã¶z
        # x deÄŸerleri iÃ§in append kullanarak liste oluÅŸtur
        x_confidence = list(future_dates) + list(future_dates)[::-1]
        # y deÄŸerleri iÃ§in append kullanarak liste oluÅŸtur
        y_confidence = list(y_upper) + list(y_lower)[::-1]
        
        fig.add_trace(go.Scatter(
            x=x_confidence,
            y=y_confidence,
            fill='toself',
            fillcolor='rgba(0, 176, 246, 0.2)',
            line=dict(color='rgba(255,255,255,0)'),
            name='Tahmin AralÄ±ÄŸÄ± (%90)',
            showlegend=True
        ))
        
        # DÃ¼zen ayarlarÄ±
        fig.update_layout(
            title=f"{days} GÃ¼nlÃ¼k Fiyat Tahmini",
            xaxis_title="Tarih",
            yaxis_title="Fiyat (TL)",
            legend_title="Tahmin",
            hovermode="x unified",
            height=500
        )
        
        return fig
    except Exception as e:
        st.error(f"Tahmin grafiÄŸi oluÅŸturma hatasÄ±: {str(e)}")
        return None

# Gemini API ile haber analizi fonksiyonu 
def analyze_news_with_gemini(url, log_container=None):
    """Gemini API kullanarak haber analizi yapar"""
    # Global deÄŸiÅŸkenleri kullan
    global gemini_pro
    global genai
    
    try:
        if gemini_pro is None:
            # EÄŸer gemini_pro deÄŸiÅŸkeni None ise, model listesindeki diÄŸer modelleri deneyelim
            try:
                import google.generativeai as genai
                
                # API anahtarÄ±nÄ± kontrol et ve yapÄ±landÄ±r
                GEMINI_API_KEY = "AIzaSyANEpZjZCV9zYtUsMJ5BBgMzkrf8yu8kM8"
                if GEMINI_API_KEY:
                    genai.configure(api_key=GEMINI_API_KEY)
                
                model_options = [
                    'gemini-2.0-pro-exp', 'gemini-2.0-flash', 'gemini-2.0-flash-001',
                    'gemini-1.5-pro-latest', 'gemini-1.5-flash-latest', 'gemini-1.5-flash-8b-exp',
                    'gemini-1.5-pro-002', 'gemini-1.5-pro-001', 'gemini-1.5-pro',
                    'gemini-1.5-flash-002', 'gemini-1.5-flash-001', 'gemini-1.5-flash',
                    'gemini-1.0-ultra', 'gemini-1.0-pro'
                ]
                
                for model_name in model_options:
                    try:
                        if log_container:
                            display_log_message(f"{model_name} modeli deneniyor...", log_container)
                        test_model = genai.GenerativeModel(model_name)
                        # Test et
                        response = test_model.generate_content("Test")
                        # BaÅŸarÄ±lÄ± ise kaydet
                        gemini_pro = test_model
                        if log_container:
                            display_log_message(f"{model_name} modeline baÄŸlantÄ± baÅŸarÄ±lÄ±!", log_container, "success")
                        break
                    except Exception as model_error:
                        if log_container:
                            display_log_message(f"{model_name} modeline baÄŸlanÄ±lamadÄ±: {str(model_error)}", log_container, "warning")
                        continue
            except Exception as genai_error:
                if log_container:
                    display_log_message(f"Genai kÃ¼tÃ¼phanesi hatasÄ±: {str(genai_error)}", log_container, "error")
            
        if gemini_pro is None:
            if log_container:
                display_log_message("HiÃ§bir Gemini API modeline baÄŸlanÄ±lamadÄ±", log_container, "warning")
            return {
                "success": False,
                "error": "Gemini API kullanÄ±lamÄ±yor"
            }
        
        if log_container:
            display_log_message(f"Gemini API ile analiz ediliyor: {url}", log_container)
        
        # Basit prompt ile haber analizi iste
        prompt = f"""
LÃ¼tfen bu haber URL'sini analiz et: {url}

Analiz iÃ§in bir JSON Ã§Ä±ktÄ±sÄ± dÃ¶ndÃ¼r, ÅŸu formatta:
{{
  "success": true,
  "title": "Haber baÅŸlÄ±ÄŸÄ±",
  "publish_date": "YayÄ±n tarihi (eÄŸer bulunursa)",
  "authors": "Yazar isimleri (eÄŸer bulunursa)",
  "content": "Ã–zet iÃ§erik",
  "sentiment": "Olumlu, NÃ¶tr veya Olumsuz",
  "sentiment_score": 0.75, // 0-1 arasÄ± bir deÄŸer, 1 en olumlu
  "ai_summary": "KÄ±sa bir Ã¶zet",
  "ai_analysis": {{
    "etki": "olumlu/olumsuz/nÃ¶tr",
    "etki_sebebi": "Bu haberin neden olumlu/olumsuz/nÃ¶tr olduÄŸuna dair kÄ±sa aÃ§Ä±klama",
    "Ã¶nemli_noktalar": ["Madde 1", "Madde 2"]
  }}
}}

EÄŸer URL'ye eriÅŸemez veya iÃ§eriÄŸi analiz edemezsen, ÅŸunu dÃ¶ndÃ¼r:
{{
  "success": false,
  "error": "Hata aÃ§Ä±klamasÄ±"
}}
"""
        
        response = gemini_pro.generate_content(prompt)
        response_text = response.text
        
        # JSON yanÄ±tÄ±nÄ± Ã§Ä±kar
        
        # YanÄ±ttan JSON kÄ±smÄ±nÄ± bul
        json_match = re.search(r'({[\s\S]*})', response_text)
        if json_match:
            json_str = json_match.group(1)
            try:
                result = json.loads(json_str)
                if log_container:
                    display_log_message("Gemini analizi baÅŸarÄ±lÄ±", log_container, "success")
                return result
            except json.JSONDecodeError as json_e:
                if log_container:
                    display_log_message(f"JSON Ã§Ã¶zÃ¼mleme hatasÄ±: {str(json_e)}", log_container, "error")
        
        if log_container:
            display_log_message("Gemini yanÄ±tÄ± iÅŸlenemedi", log_container, "error")
        return {
            "success": False,
            "error": "YanÄ±t iÅŸlenemedi"
        }
        
    except Exception as e:
        if log_container:
            display_log_message(f"Gemini analiz hatasÄ±: {str(e)}", log_container, "error")
        return {
            "success": False,
            "error": str(e)
        }